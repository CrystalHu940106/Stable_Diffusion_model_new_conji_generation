{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Quick test script to verify all fixes are working correctly\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add scripts directory to path\n",
        "sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'scripts'))\n",
        "\n",
        "from stable_diffusion_kanji import VAE, UNet2DConditionModel, DDPMScheduler, StableDiffusionPipeline\n",
        "\n",
        "def test_vae():\n",
        "    \"\"\"Test VAE with KL divergence loss\"\"\"\n",
        "    print(\"\ud83e\uddea Testing VAE...\")\n",
        "    \n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    vae = VAE(hidden_dims=[128, 256, 512]).to(device)\n",
        "    \n",
        "    # Test input\n",
        "    test_image = torch.randn(4, 3, 128, 128).to(device)\n",
        "    \n",
        "    try:\n",
        "        # Encode with KL loss\n",
        "        latents, mu, logvar, kl_loss = vae.encode(test_image)\n",
        "        reconstructed = vae.decode(latents)\n",
        "        \n",
        "        print(f\"\u2705 VAE test passed:\")\n",
        "        print(f\"   \u2022 Input: {test_image.shape}\")\n",
        "        print(f\"   \u2022 Latents: {latents.shape}\")\n",
        "        print(f\"   \u2022 Mu: {mu.shape}\")\n",
        "        print(f\"   \u2022 Logvar: {logvar.shape}\")\n",
        "        print(f\"   \u2022 KL Loss: {kl_loss.item():.6f}\")\n",
        "        print(f\"   \u2022 Reconstructed: {reconstructed.shape}\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u274c VAE test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "def test_unet():\n",
        "    \"\"\"Test UNet without debug prints\"\"\"\n",
        "    print(\"\\n\ud83e\uddea Testing UNet...\")\n",
        "    \n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    unet = UNet2DConditionModel(\n",
        "        model_channels=128,\n",
        "        num_res_blocks=2,\n",
        "        channel_mult=(1, 2, 4),\n",
        "        num_heads=8\n",
        "    ).to(device)\n",
        "    \n",
        "    # Test input\n",
        "    test_latents = torch.randn(8, 4, 16, 16).to(device)  # Batch size 8\n",
        "    test_timesteps = torch.randint(0, 1000, (8,)).to(device)\n",
        "    test_context = torch.randn(8, 77, 512).to(device)\n",
        "    \n",
        "    try:\n",
        "        # Forward pass (should be silent - no debug prints)\n",
        "        output = unet(test_latents, test_timesteps, test_context)\n",
        "        \n",
        "        print(f\"\u2705 UNet test passed:\")\n",
        "        print(f\"   \u2022 Input latents: {test_latents.shape}\")\n",
        "        print(f\"   \u2022 Timesteps: {test_timesteps.shape}\")\n",
        "        print(f\"   \u2022 Context: {test_context.shape}\")\n",
        "        print(f\"   \u2022 Output: {output.shape}\")\n",
        "        print(f\"   \u2022 No debug prints detected \u2705\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u274c UNet test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "def test_scheduler():\n",
        "    \"\"\"Test DDPM scheduler\"\"\"\n",
        "    print(\"\\n\ud83e\uddea Testing DDPM Scheduler...\")\n",
        "    \n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
        "    \n",
        "    # Test input\n",
        "    test_latents = torch.randn(4, 4, 16, 16).to(device)\n",
        "    test_noise = torch.randn_like(test_latents)\n",
        "    test_timesteps = torch.randint(0, 1000, (4,)).to(device)\n",
        "    \n",
        "    try:\n",
        "        # Add noise\n",
        "        noisy_latents = scheduler.add_noise(test_latents, test_noise, test_timesteps)\n",
        "        \n",
        "        # Denoise step\n",
        "        denoised = scheduler.step(test_noise, test_timesteps, noisy_latents)\n",
        "        \n",
        "        print(f\"\u2705 Scheduler test passed:\")\n",
        "        print(f\"   \u2022 Original: {test_latents.shape}\")\n",
        "        print(f\"   \u2022 Noisy: {noisy_latents.shape}\")\n",
        "        print(f\"   \u2022 Denoised: {denoised.shape}\")\n",
        "        print(f\"   \u2022 Timesteps: {test_timesteps}\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Scheduler test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "def test_pipeline():\n",
        "    \"\"\"Test complete pipeline\"\"\"\n",
        "    print(\"\\n\ud83e\uddea Testing Stable Diffusion Pipeline...\")\n",
        "    \n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    try:\n",
        "        pipeline = StableDiffusionPipeline(device=device)\n",
        "        \n",
        "        print(f\"\u2705 Pipeline test passed:\")\n",
        "        print(f\"   \u2022 Device: {device}\")\n",
        "        print(f\"   \u2022 VAE: {type(pipeline.vae).__name__}\")\n",
        "        print(f\"   \u2022 UNet: {type(pipeline.unet).__name__}\")\n",
        "        print(f\"   \u2022 Scheduler: {type(pipeline.scheduler).__name__}\")\n",
        "        print(f\"   \u2022 Text Encoder: {type(pipeline.text_encoder).__name__}\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Pipeline test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "def test_batch_processing():\n",
        "    \"\"\"Test batch processing with larger batch sizes\"\"\"\n",
        "    print(\"\\n\ud83e\uddea Testing Batch Processing...\")\n",
        "    \n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    # Test different batch sizes\n",
        "    batch_sizes = [4, 8, 16]\n",
        "    \n",
        "    for batch_size in batch_sizes:\n",
        "        try:\n",
        "            print(f\"   Testing batch size: {batch_size}\")\n",
        "            \n",
        "            # Create test data\n",
        "            test_images = torch.randn(batch_size, 3, 128, 128).to(device)\n",
        "            test_prompts = [f\"test prompt {i}\" for i in range(batch_size)]\n",
        "            \n",
        "            # Initialize models\n",
        "            vae = VAE(hidden_dims=[128, 256]).to(device)\n",
        "            unet = UNet2DConditionModel(\n",
        "                model_channels=128,\n",
        "                num_res_blocks=2,\n",
        "                channel_mult=(1, 2),\n",
        "                num_heads=8\n",
        "            ).to(device)\n",
        "            \n",
        "            # Test VAE encoding\n",
        "            latents, mu, logvar, kl_loss = vae.encode(test_images)\n",
        "            \n",
        "            # Test UNet forward pass\n",
        "            test_latents = torch.randn(batch_size, 4, 16, 16).to(device)\n",
        "            test_timesteps = torch.randint(0, 1000, (batch_size,)).to(device)\n",
        "            test_context = torch.randn(batch_size, 77, 512).to(device)\n",
        "            \n",
        "            output = unet(test_latents, test_timesteps, test_context)\n",
        "            \n",
        "            print(f\"      \u2705 Batch size {batch_size}: VAE {latents.shape}, UNet {output.shape}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"      \u274c Batch size {batch_size} failed: {e}\")\n",
        "            return False\n",
        "    \n",
        "    return True\n",
        "\n",
        "def main():\n",
        "    \"\"\"Run all tests\"\"\"\n",
        "    print(\"\ud83c\udf8c Testing All Fixes\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    tests = [\n",
        "        (\"VAE with KL Loss\", test_vae),\n",
        "        (\"UNet without Debug Prints\", test_unet),\n",
        "        (\"DDPM Scheduler\", test_scheduler),\n",
        "        (\"Complete Pipeline\", test_pipeline),\n",
        "        (\"Batch Processing\", test_batch_processing)\n",
        "    ]\n",
        "    \n",
        "    passed = 0\n",
        "    total = len(tests)\n",
        "    \n",
        "    for test_name, test_func in tests:\n",
        "        print(f\"\\n{'='*20} {test_name} {'='*20}\")\n",
        "        if test_func():\n",
        "            passed += 1\n",
        "            print(f\"\u2705 {test_name} PASSED\")\n",
        "        else:\n",
        "            print(f\"\u274c {test_name} FAILED\")\n",
        "    \n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"\ud83d\udcca Test Results: {passed}/{total} tests passed\")\n",
        "    \n",
        "    if passed == total:\n",
        "        print(\"\ud83c\udf89 All tests passed! All fixes are working correctly.\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"\u26a0\ufe0f  Some tests failed. Please check the errors above.\")\n",
        "        return False\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    success = main()\n",
        "    sys.exit(0 if success else 1)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}