#!/usr/bin/env python3
"""
testæ”¹è¿›åofStable Diffusionmodel
æ¯”è¾ƒæ”¹è¿›å‰åofæ€§canå·®å¼‚
"""

import torch
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from stable_diffusion_kanji import StableDiffusionPipeline as OriginalPipeline
from improved_stable_diffusion import ImprovedStableDiffusionPipeline as ImprovedPipeline
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import time

def test_model_comparison():
    """æ¯”è¾ƒåŸå§‹modelå’Œæ”¹è¿›modelofæ€§can"""
    
    print("ğŸŒ æ¨¡å‹æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("=" * 50)
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # testæ¦‚å¿µ
    concepts = ["water", "future"]
    
    # teståŸå§‹model
    print(f"\nğŸ” æµ‹è¯•åŸå§‹æ¨¡å‹...")
    try:
        original_pipeline = OriginalPipeline(device=device)
        print("âœ… åŸå§‹æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        
        for concept in concepts:
            print(f"\nğŸŒŠ åŸå§‹æ¨¡å‹ç”Ÿæˆ '{concept}'...")
            start_time = time.time()
            
            try:
                result = original_pipeline.generate(
                    concept,
                    height=128,
                    width=128,
                    num_inference_steps=50,
                    guidance_scale=12.0,
                    seed=42
                )
                
                generation_time = time.time() - start_time
                print(f"   â±ï¸  ç”Ÿæˆæ—¶é—´: {generation_time:.2f}ç§’")
                
                # convertä¸ºPILimage
                if isinstance(result, torch.Tensor):
                    result = (result + 1) / 2
                    result = torch.clamp(result, 0, 1)
                    img_array = result.squeeze(0).permute(1, 2, 0).cpu().numpy()
                    pil_image = Image.fromarray((img_array * 255).astype(np.uint8))
                else:
                    pil_image = result
                
                # ä¿å­˜ç»“æœ
                output_path = f"original_{concept}.png"
                pil_image.save(output_path)
                print(f"   ğŸ’¾ å·²ä¿å­˜: {output_path}")
                
                # åˆ†æimagequality
                img_array = np.array(pil_image.convert('L'))
                print(f"   ğŸ“Š å›¾åƒç»Ÿè®¡:")
                print(f"      â€¢ å°ºå¯¸: {img_array.shape}")
                print(f"      â€¢ æœ€å°å€¼: {img_array.min()}")
                print(f"      â€¢ æœ€å¤§å€¼: {img_array.max()}")
                print(f"      â€¢ å¹³å‡å€¼: {img_array.mean():.2f}")
                print(f"      â€¢ æ ‡å‡†å·®: {img_array.std():.2f}")
                
            except Exception as e:
                print(f"   âŒ ç”Ÿæˆå¤±è´¥: {e}")
                
    except Exception as e:
        print(f"âŒ åŸå§‹æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
    
    # testæ”¹è¿›model
    print(f"\nğŸ” æµ‹è¯•æ”¹è¿›æ¨¡å‹...")
    try:
        improved_pipeline = ImprovedPipeline(device=device)
        print("âœ… æ”¹è¿›æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        
        for concept in concepts:
            print(f"\nğŸŒŠ æ”¹è¿›æ¨¡å‹ç”Ÿæˆ '{concept}'...")
            start_time = time.time()
            
            try:
                result = improved_pipeline.generate(
                    concept,
                    height=128,
                    width=128,
                    num_inference_steps=50,
                    guidance_scale=7.5,  # usingå®˜æ–¹æ¨èofguidance scale
                    seed=42
                )
                
                generation_time = time.time() - start_time
                print(f"   â±ï¸  ç”Ÿæˆæ—¶é—´: {generation_time:.2f}ç§’")
                
                # convertä¸ºPILimage
                if isinstance(result, torch.Tensor):
                    result = (result + 1) / 2
                    result = torch.clamp(result, 0, 1)
                    img_array = result.squeeze(0).permute(1, 2, 0).cpu().numpy()
                    pil_image = Image.fromarray((img_array * 255).astype(np.uint8))
                else:
                    pil_image = result
                
                # ä¿å­˜ç»“æœ
                output_path = f"improved_{concept}.png"
                pil_image.save(output_path)
                print(f"   ğŸ’¾ å·²ä¿å­˜: {output_path}")
                
                # åˆ†æimagequality
                img_array = np.array(pil_image.convert('L'))
                print(f"   ğŸ“Š å›¾åƒç»Ÿè®¡:")
                print(f"      â€¢ å°ºå¯¸: {img_array.shape}")
                print(f"      â€¢ æœ€å°å€¼: {img_array.min()}")
                print(f"      â€¢ æœ€å¤§å€¼: {img_array.max()}")
                print(f"      â€¢ å¹³å‡å€¼: {img_array.mean():.2f}")
                print(f"      â€¢ æ ‡å‡†å·®: {img_array.std():.2f}")
                
            except Exception as e:
                print(f"   âŒ ç”Ÿæˆå¤±è´¥: {e}")
                
    except Exception as e:
        print(f"âŒ æ”¹è¿›æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
    
    # generationå¯¹æ¯”å›¾
    print(f"\nğŸ¨ ç”Ÿæˆå¯¹æ¯”å›¾...")
    try:
        concepts = ["water", "future"]
        fig, axes = plt.subplots(len(concepts), 2, figsize=(12, 10))
        
        for i, concept in enumerate(concepts):
            # åŸå§‹modelç»“æœ
            original_file = f"original_{concept}.png"
            if os.path.exists(original_file):
                original_img = Image.open(original_file)
                axes[i, 0].imshow(original_img, cmap='gray')
                axes[i, 0].set_title(f'{concept} - åŸå§‹æ¨¡å‹')
                axes[i, 0].axis('off')
            else:
                axes[i, 0].text(0.5, 0.5, f'{concept}\nåŸå§‹æ¨¡å‹\nç”Ÿæˆå¤±è´¥', 
                              ha='center', va='center', transform=axes[i, 0].transAxes)
                axes[i, 0].set_title(f'{concept} - åŸå§‹æ¨¡å‹')
                axes[i, 0].axis('off')
            
            # æ”¹è¿›modelç»“æœ
            improved_file = f"improved_{concept}.png"
            if os.path.exists(improved_file):
                improved_img = Image.open(improved_file)
                axes[i, 1].imshow(improved_img, cmap='gray')
                axes[i, 1].set_title(f'{concept} - æ”¹è¿›æ¨¡å‹')
                axes[i, 1].axis('off')
            else:
                axes[i, 1].text(0.5, 0.5, f'{concept}\næ”¹è¿›æ¨¡å‹\nç”Ÿæˆå¤±è´¥', 
                              ha='center', va='center', transform=axes[i, 1].transAxes)
                axes[i, 1].set_title(f'{concept} - æ”¹è¿›æ¨¡å‹')
                axes[i, 1].axis('off')
        
        plt.tight_layout()
        comparison_path = 'model_comparison.png'
        plt.savefig(comparison_path, dpi=150, bbox_inches='tight')
        print(f"âœ… å¯¹æ¯”å›¾å·²ä¿å­˜: {comparison_path}")
        plt.show()
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¯¹æ¯”å›¾å¤±è´¥: {e}")
    
    print(f"\nğŸ‰ æ¨¡å‹å¯¹æ¯”æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    for concept in concepts:
        print(f"   â€¢ original_{concept}.png - åŸå§‹æ¨¡å‹ç»“æœ")
        print(f"   â€¢ improved_{concept}.png - æ”¹è¿›æ¨¡å‹ç»“æœ")
    print(f"   â€¢ model_comparison.png - å¯¹æ¯”å›¾")

def analyze_improvements():
    """åˆ†ææ”¹è¿›ç‚¹"""
    
    print(f"\nğŸ” æ”¹è¿›ç‚¹åˆ†æ")
    print("=" * 50)
    
    improvements = [
        "ğŸ—ï¸  æ¶æ„æ”¹è¿›:",
        "   â€¢ ä½¿ç”¨GroupNormæ›¿ä»£BatchNormï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§",
        "   â€¢ ä½¿ç”¨SiLUæ¿€æ´»å‡½æ•°ï¼Œæ›¿ä»£LeakyReLU",
        "   â€¢ æ›´æ·±çš„ç½‘ç»œç»“æ„ï¼Œå¢åŠ æ¨¡å‹å®¹é‡",
        "",
        "ğŸ¯ è®­ç»ƒç­–ç•¥æ”¹è¿›:",
        "   â€¢ å€Ÿé‰´å®˜æ–¹çš„æ—¶é—´åµŒå…¥ç½‘ç»œè®¾è®¡",
        "   â€¢ æ”¹è¿›çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶",
        "   â€¢ æ›´å¥½çš„æ®‹å·®å—è®¾è®¡",
        "",
        "âš™ï¸  æ¨ç†ä¼˜åŒ–:",
        "   â€¢ ä½¿ç”¨å®˜æ–¹æ¨èçš„guidance scale (7.5)",
        "   â€¢ æ”¹è¿›çš„DDPMè°ƒåº¦å™¨",
        "   â€¢ æ›´ç¨³å®šçš„å»å™ªè¿‡ç¨‹",
        "",
        "ğŸ“ æç¤ºå·¥ç¨‹:",
        "   â€¢ æ›´è¯¦ç»†çš„æ±‰å­—æè¿°",
        "   â€¢ ä¸“ä¸šè´¨é‡çš„è‰ºæœ¯é£æ ¼æè¿°",
        "   â€¢ å¼ºè°ƒå¯¹æ¯”åº¦å’Œæ¸…æ™°åº¦"
    ]
    
    for improvement in improvements:
        print(improvement)

if __name__ == "__main__":
    test_model_comparison()
    analyze_improvements()
