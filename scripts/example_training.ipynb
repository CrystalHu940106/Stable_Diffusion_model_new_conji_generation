{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Example: Using Kanji Dataset for Stable Diffusion Training\n",
        "\n",
        "This script demonstrates how to load and prepare the Kanji dataset\n",
        "for training a stable diffusion model.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class KanjiDataset(Dataset):\n",
        "    \"\"\"Custom Dataset for Kanji characters\"\"\"\n",
        "    \n",
        "    def __init__(self, dataset_path, transform=None):\n",
        "        self.dataset_path = Path(dataset_path)\n",
        "        self.transform = transform\n",
        "        \n",
        "        # Load dataset metadata\n",
        "        metadata_path = self.dataset_path / \"metadata\" / \"dataset.json\"\n",
        "        with open(metadata_path, 'r', encoding='utf-8') as f:\n",
        "            self.data = json.load(f)\n",
        "        \n",
        "        print(f\"Loaded {len(self.data)} Kanji entries\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        entry = self.data[idx]\n",
        "        \n",
        "        # Load image\n",
        "        image_path = self.dataset_path / \"images\" / entry['image_file']\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        \n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        # Return image and prompt\n",
        "        return {\n",
        "            'image': image,\n",
        "            'prompt': entry['prompt'],\n",
        "            'kanji': entry['kanji'],\n",
        "            'meanings': entry['meanings']\n",
        "        }\n",
        "\n",
        "def create_transforms(image_size=128):\n",
        "    \"\"\"Create transforms for training - optimized for low resolution\"\"\"\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        # Normalize to [-1, 1] for stable diffusion\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "def create_augmented_transforms(image_size=128):\n",
        "    \"\"\"Create transforms with data augmentation - optimized for low resolution\"\"\"\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.RandomRotation(5),  # Small rotations\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Small translations\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1),  # Slight brightness/contrast\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    \"\"\"Custom collate function to handle variable-length prompts\"\"\"\n",
        "    images = torch.stack([item['image'] for item in batch])\n",
        "    prompts = [item['prompt'] for item in batch]\n",
        "    kanji_chars = [item['kanji'] for item in batch]\n",
        "    meanings = [item['meanings'] for item in batch]\n",
        "    \n",
        "    return {\n",
        "        'image': images,\n",
        "        'prompt': prompts,\n",
        "        'kanji': kanji_chars,\n",
        "        'meanings': meanings\n",
        "    }\n",
        "\n",
        "def example_training_setup():\n",
        "    \"\"\"Example of how to set up training with the dataset\"\"\"\n",
        "    \n",
        "    # Create dataset\n",
        "    transform = create_transforms()\n",
        "    dataset = KanjiDataset(\"kanji_dataset\", transform=transform)\n",
        "    \n",
        "    # Create data loader with custom collate function - optimized for CPU training\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=4,  # Reduced for CPU training\n",
        "        shuffle=True,\n",
        "        num_workers=0,  # Set to 0 to avoid multiprocessing issues\n",
        "        collate_fn=custom_collate_fn\n",
        "    )\n",
        "    \n",
        "    print(f\"Dataset size: {len(dataset)}\")\n",
        "    print(f\"Number of batches: {len(dataloader)}\")\n",
        "    \n",
        "    # Example: iterate through a few batches\n",
        "    print(\"\\n=== Example Batches ===\")\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        if i >= 3:  # Show first 3 batches\n",
        "            break\n",
        "            \n",
        "        images = batch['image']\n",
        "        prompts = batch['prompt']\n",
        "        kanji_chars = batch['kanji']\n",
        "        \n",
        "        print(f\"Batch {i+1}:\")\n",
        "        print(f\"  Images shape: {images.shape}\")\n",
        "        print(f\"  Sample prompts: {prompts[:3]}\")\n",
        "        print(f\"  Sample Kanji: {kanji_chars[:3]}\")\n",
        "        print()\n",
        "\n",
        "def example_validation_split():\n",
        "    \"\"\"Example of creating train/validation split\"\"\"\n",
        "    \n",
        "    # Load full dataset\n",
        "    transform = create_transforms()\n",
        "    full_dataset = KanjiDataset(\"kanji_dataset\", transform=transform)\n",
        "    \n",
        "    # Split into train/validation (80/20)\n",
        "    train_size = int(0.8 * len(full_dataset))\n",
        "    val_size = len(full_dataset) - train_size\n",
        "    \n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
        "        full_dataset, [train_size, val_size]\n",
        "    )\n",
        "    \n",
        "    print(f\"Training set: {len(train_dataset)} samples\")\n",
        "    print(f\"Validation set: {len(val_dataset)} samples\")\n",
        "    \n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, \n",
        "        batch_size=8, \n",
        "        shuffle=True, \n",
        "        num_workers=0,\n",
        "        collate_fn=custom_collate_fn\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset, \n",
        "        batch_size=8, \n",
        "        shuffle=False, \n",
        "        num_workers=0,\n",
        "        collate_fn=custom_collate_fn\n",
        "    )\n",
        "    \n",
        "    return train_loader, val_loader\n",
        "\n",
        "def example_prompt_engineering():\n",
        "    \"\"\"Example of different prompt engineering approaches\"\"\"\n",
        "    \n",
        "    dataset = KanjiDataset(\"kanji_dataset\")\n",
        "    \n",
        "    print(\"=== Prompt Engineering Examples ===\")\n",
        "    \n",
        "    # Get a few examples\n",
        "    examples = [dataset[i] for i in range(5)]\n",
        "    \n",
        "    for i, example in enumerate(examples):\n",
        "        kanji = example['kanji']\n",
        "        meanings = example['meanings']\n",
        "        \n",
        "        print(f\"\\n{i+1}. Kanji: {kanji}\")\n",
        "        print(f\"   Meanings: {meanings}\")\n",
        "        \n",
        "        # Different prompt formats\n",
        "        prompts = [\n",
        "            f\"kanji character {kanji}: {', '.join(meanings)}\",\n",
        "            f\"japanese kanji {kanji} meaning {meanings[0]}\",\n",
        "            f\"black and white kanji character {kanji}\",\n",
        "            f\"calligraphy kanji {kanji} with meaning {', '.join(meanings[:2])}\",\n",
        "            f\"traditional japanese writing {kanji}\"\n",
        "        ]\n",
        "        \n",
        "        for j, prompt in enumerate(prompts):\n",
        "            print(f\"   Prompt {j+1}: {prompt}\")\n",
        "\n",
        "def example_simple_usage():\n",
        "    \"\"\"Simple example without DataLoader\"\"\"\n",
        "    \n",
        "    print(\"=== Simple Dataset Usage ===\")\n",
        "    \n",
        "    # Create dataset without transforms for simple inspection\n",
        "    dataset = KanjiDataset(\"kanji_dataset\")\n",
        "    \n",
        "    # Show a few examples\n",
        "    for i in range(5):\n",
        "        example = dataset[i]\n",
        "        print(f\"\\n{i+1}. Kanji: {example['kanji']}\")\n",
        "        print(f\"   Prompt: {example['prompt']}\")\n",
        "        print(f\"   Meanings: {example['meanings']}\")\n",
        "        print(f\"   Image size: {example['image'].size}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function demonstrating dataset usage\"\"\"\n",
        "    \n",
        "    print(\"=== Kanji Dataset Training Example ===\\n\")\n",
        "    \n",
        "    # Check if dataset exists\n",
        "    if not Path(\"kanji_dataset\").exists():\n",
        "        print(\"\u274c Dataset not found! Please run process_kanji_data.py first.\")\n",
        "        return\n",
        "    \n",
        "    # Example 1: Simple usage\n",
        "    print(\"1. Simple Dataset Usage\")\n",
        "    example_simple_usage()\n",
        "    \n",
        "    # Example 2: Basic training setup\n",
        "    print(\"\\n2. Basic Training Setup\")\n",
        "    example_training_setup()\n",
        "    \n",
        "    # Example 3: Train/validation split\n",
        "    print(\"\\n3. Train/Validation Split\")\n",
        "    train_loader, val_loader = example_validation_split()\n",
        "    \n",
        "    # Example 4: Prompt engineering\n",
        "    print(\"\\n4. Prompt Engineering\")\n",
        "    example_prompt_engineering()\n",
        "    \n",
        "    print(\"\\n=== Training Recommendations (CPU Optimized) ===\")\n",
        "    print(\"\u2022 Use batch size 2-4 for CPU training\")\n",
        "    print(\"\u2022 Learning rate: 1e-4 to 5e-4 (higher for faster convergence)\")\n",
        "    print(\"\u2022 Image resolution: 128x128 (faster than 256x256)\")\n",
        "    print(\"\u2022 Training epochs: 3-5 epochs should be sufficient\")\n",
        "    print(\"\u2022 Consider data augmentation for better generalization\")\n",
        "    print(\"\u2022 Monitor validation loss to prevent overfitting\")\n",
        "    print(\"\u2022 Use custom collate function for variable-length prompts\")\n",
        "    print(\"\u2022 Dataset size: 6,410 entries is sufficient for small model\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main() "
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}