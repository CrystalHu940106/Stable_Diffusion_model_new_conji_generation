{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Test Concept Generation - Verify Modern Concept Kanji Generation\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# Import our Stable Diffusion components\n",
        "from stable_diffusion_kanji import (\n",
        "    VAE, UNet2DConditionModel, DDPMScheduler, \n",
        "    StableDiffusionPipeline\n",
        ")\n",
        "\n",
        "def test_text_encoding():\n",
        "    \"\"\"Test CLIP text encoding functionality\"\"\"\n",
        "    print(\"\ud83e\uddea Testing CLIP Text Encoding\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Initialize pipeline\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"Using device: {device}\")\n",
        "    \n",
        "    try:\n",
        "        pipeline = StableDiffusionPipeline(device=device)\n",
        "        \n",
        "        # Test prompts\n",
        "        test_prompts = [\n",
        "            \"kanji character meaning: success, achieve, accomplish\",\n",
        "            \"kanji character meaning: failure, lose, defeat\",\n",
        "            \"kanji character meaning: novel, new, creative\",\n",
        "            \"kanji character meaning: funny, humorous, amusing\",\n",
        "            \"kanji character meaning: culture, tradition, heritage\"\n",
        "        ]\n",
        "        \n",
        "        for prompt in test_prompts:\n",
        "            print(f\"\\n\ud83d\udcdd Testing: {prompt}\")\n",
        "            embeddings = pipeline.encode_text(prompt)\n",
        "            print(f\"   Shape: {embeddings.shape}\")\n",
        "            print(f\"   Device: {embeddings.device}\")\n",
        "            print(f\"   Dtype: {embeddings.dtype}\")\n",
        "            \n",
        "            # Check if embeddings are reasonable\n",
        "            if embeddings.abs().mean() > 0:\n",
        "                print(f\"   \u2705 Embeddings look good\")\n",
        "            else:\n",
        "                print(f\"   \u26a0\ufe0f  Embeddings might be zero\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Text encoding test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "def test_diffusion_scheduler():\n",
        "    \"\"\"Test DDPM scheduler functionality\"\"\"\n",
        "    print(\"\\n\ud83e\uddea Testing DDPM Scheduler\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    try:\n",
        "        scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
        "        \n",
        "        # Test timestep setting\n",
        "        print(\"\ud83d\udcca Testing timestep management:\")\n",
        "        scheduler.set_timesteps(50)\n",
        "        print(f\"   Inference timesteps: {scheduler.timesteps.shape}\")\n",
        "        print(f\"   First few timesteps: {scheduler.timesteps[:5].tolist()}\")\n",
        "        \n",
        "        # Test noise addition\n",
        "        print(\"\\n\ud83d\udcca Testing noise addition:\")\n",
        "        latents = torch.randn(2, 4, 32, 32)\n",
        "        noise = torch.randn(2, 4, 32, 32)\n",
        "        timesteps = torch.tensor([100, 500])\n",
        "        \n",
        "        noisy_latents = scheduler.add_noise(latents, noise, timesteps)\n",
        "        print(f\"   Original shape: {latents.shape}\")\n",
        "        print(f\"   Noisy shape: {noisy_latents.shape}\")\n",
        "        print(f\"   Noise added successfully: {not torch.allclose(latents, noisy_latents)}\")\n",
        "        \n",
        "        # Test denoising step\n",
        "        print(\"\\n\ud83d\udcca Testing denoising step:\")\n",
        "        model_output = torch.randn(2, 4, 32, 32)\n",
        "        denoised = scheduler.step(model_output, timesteps[0], noisy_latents[0])\n",
        "        print(f\"   Denoised shape: {denoised.shape}\")\n",
        "        print(f\"   Denoising successful: {denoised.shape == latents[0].shape}\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Scheduler test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "def test_concept_generation():\n",
        "    \"\"\"Test modern concept generation\"\"\"\n",
        "    print(\"\\n\ud83e\uddea Testing Concept Generation\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Initialize pipeline\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"Using device: {device}\")\n",
        "    \n",
        "    try:\n",
        "        pipeline = StableDiffusionPipeline(device=device)\n",
        "        \n",
        "        # Modern concepts to test\n",
        "        modern_concepts = {\n",
        "            'youtube': 'kanji character meaning: video sharing platform, streaming content',\n",
        "            'gundam': 'kanji character meaning: giant robot mecha, futuristic warfare',\n",
        "            'ai': 'kanji character meaning: artificial intelligence, machine learning',\n",
        "            'crypto': 'kanji character meaning: digital cryptocurrency, blockchain',\n",
        "            'internet': 'kanji character meaning: global network, digital connectivity'\n",
        "        }\n",
        "        \n",
        "        results = {}\n",
        "        \n",
        "        for concept, prompt in modern_concepts.items():\n",
        "            print(f\"\\n\ud83c\udfaf Testing concept: {concept.upper()}\")\n",
        "            print(f\"   Prompt: {prompt}\")\n",
        "            \n",
        "            try:\n",
        "                # Generate with fewer steps for testing\n",
        "                generated = pipeline.generate(prompt, num_inference_steps=20)\n",
        "                results[concept] = generated\n",
        "                print(f\"   \u2705 Generated successfully: {generated.shape}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"   \u274c Generation failed: {e}\")\n",
        "                results[concept] = None\n",
        "        \n",
        "        # Display results\n",
        "        if any(v is not None for v in results.values()):\n",
        "            display_test_results(results)\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Concept generation test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "def display_test_results(results):\n",
        "    \"\"\"Display test generation results\"\"\"\n",
        "    print(f\"\\n\ud83d\uddbc\ufe0f  Displaying Test Results\")\n",
        "    \n",
        "    # Filter successful generations\n",
        "    successful_results = {k: v for k, v in results.items() if v is not None}\n",
        "    \n",
        "    if not successful_results:\n",
        "        print(\"\u274c No successful generations to display\")\n",
        "        return\n",
        "    \n",
        "    # Create subplot\n",
        "    num_concepts = len(successful_results)\n",
        "    fig, axes = plt.subplots(1, num_concepts, figsize=(4*num_concepts, 4))\n",
        "    \n",
        "    if num_concepts == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for i, (concept, generated) in enumerate(successful_results.items()):\n",
        "        try:\n",
        "            # Convert tensor to image\n",
        "            if generated.dim() == 4:\n",
        "                generated = generated.squeeze(0)\n",
        "            \n",
        "            # Denormalize from [-1, 1] to [0, 1]\n",
        "            generated = (generated + 1) / 2\n",
        "            generated = torch.clamp(generated, 0, 1)\n",
        "            \n",
        "            # Convert to numpy\n",
        "            img_array = generated.permute(1, 2, 0).numpy()\n",
        "            \n",
        "            # Display\n",
        "            axes[i].imshow(img_array)\n",
        "            axes[i].set_title(f'{concept.upper()}', fontsize=12)\n",
        "            axes[i].axis('off')\n",
        "            \n",
        "        except Exception as e:\n",
        "            axes[i].text(0.5, 0.5, f'Error\\n{e}', ha='center', va='center')\n",
        "            axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save results\n",
        "    output_path = \"test_concept_results.png\"\n",
        "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"\ud83d\udcbe Test results saved to: {output_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "def test_training_components():\n",
        "    \"\"\"Test training components\"\"\"\n",
        "    print(\"\\n\ud83e\uddea Testing Training Components\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    try:\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        \n",
        "        # Test VAE\n",
        "        print(\"\ud83d\udcca Testing VAE:\")\n",
        "        vae = VAE().to(device)\n",
        "        test_image = torch.randn(2, 3, 128, 128).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            encoded = vae.encode(test_image)\n",
        "            decoded = vae.decode(encoded)\n",
        "        \n",
        "        print(f\"   Input shape: {test_image.shape}\")\n",
        "        print(f\"   Encoded shape: {encoded.shape}\")\n",
        "        print(f\"   Decoded shape: {decoded.shape}\")\n",
        "        print(f\"   VAE working: {decoded.shape == test_image.shape}\")\n",
        "        \n",
        "        # Test UNet\n",
        "        print(\"\\n\ud83d\udcca Testing UNet:\")\n",
        "        unet = UNet2DConditionModel().to(device)\n",
        "        test_latents = torch.randn(2, 4, 32, 32).to(device)\n",
        "        test_timesteps = torch.tensor([100, 200]).to(device)\n",
        "        test_context = torch.randn(2, 77, 768).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output = unet(test_latents, test_timesteps, test_context)\n",
        "        \n",
        "        print(f\"   Input latents: {test_latents.shape}\")\n",
        "        print(f\"   Output: {output.shape}\")\n",
        "        print(f\"   UNet working: {output.shape == test_latents.shape}\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Training components test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main test function\"\"\"\n",
        "    print(\"\ud83e\uddea Stable Diffusion Concept Generation Tests\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Run all tests\n",
        "    tests = [\n",
        "        (\"Text Encoding\", test_text_encoding),\n",
        "        (\"Diffusion Scheduler\", test_diffusion_scheduler),\n",
        "        (\"Training Components\", test_training_components),\n",
        "        (\"Concept Generation\", test_concept_generation)\n",
        "    ]\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for test_name, test_func in tests:\n",
        "        print(f\"\\n{'='*20} {test_name} {'='*20}\")\n",
        "        try:\n",
        "            success = test_func()\n",
        "            results[test_name] = success\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c Test {test_name} crashed: {e}\")\n",
        "            results[test_name] = False\n",
        "    \n",
        "    # Summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"\ud83d\udccb TEST SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    passed = sum(results.values())\n",
        "    total = len(results)\n",
        "    \n",
        "    for test_name, success in results.items():\n",
        "        status = \"\u2705 PASS\" if success else \"\u274c FAIL\"\n",
        "        print(f\"{status} {test_name}\")\n",
        "    \n",
        "    print(f\"\\nOverall: {passed}/{total} tests passed\")\n",
        "    \n",
        "    if passed == total:\n",
        "        print(\"\ud83c\udf89 All tests passed! Ready for training and generation.\")\n",
        "    else:\n",
        "        print(\"\u26a0\ufe0f  Some tests failed. Please check the implementation.\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}