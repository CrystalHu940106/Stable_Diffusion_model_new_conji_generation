{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Google Colab优化的Stable Diffusion训练脚本\n",
    "专门为Colab GPU环境优化，包含自动检测和性能优化\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gc\n",
    "\n",
    "# addwhen前目录to路径\n",
    "sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "from improved_stable_diffusion import (\n",
    "    ImprovedStableDiffusionPipeline,\n",
    "    ImprovedVAE,\n",
    "    ImprovedUNet2DConditionModel,\n",
    "    ImprovedDDPMScheduler\n",
    ")\n",
    "\n",
    "class ColabOptimizedTrainer:\n",
    "    \"\"\"\n",
    "    Colab优化的训练器\n",
    "    \"\"\"\n",
    "    def __init__(self, device='auto'):\n",
    "        # 自动检测设备\n",
    "        if device == 'auto':\n",
    "            if torch.cuda.is_available():\n",
    "                self.device = 'cuda'\n",
    "                print(f\"🚀 检测toCUDA设备: {torch.cuda.get_device_name()}\")\n",
    "                print(f\"   • GPU内存: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "                print(f\"   • CUDAversion: {torch.version.cuda}\")\n",
    "            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "                self.device = 'mps'\n",
    "                print(\"🍎 检测toApple Silicon (MPS)\")\n",
    "            else:\n",
    "                self.device = 'cpu'\n",
    "                print(\"💻 usingCPUtraining\")\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        # initializationmodel\n",
    "        self.vae = ImprovedVAE().to(self.device)\n",
    "        self.unet = ImprovedUNet2DConditionModel(\n",
    "            in_channels=4,\n",
    "            out_channels=4,\n",
    "            model_channels=128,\n",
    "            channel_mult=(1, 2, 4, 8),\n",
    "            attention_resolutions=(8, 16),\n",
    "            context_dim=512\n",
    "        ).to(self.device)\n",
    "        self.scheduler = ImprovedDDPMScheduler()\n",
    "        \n",
    "        # 优化器set\n",
    "        self.optimizer = optim.AdamW([\n",
    "            {'params': self.vae.parameters(), 'lr': 1e-4},\n",
    "            {'params': self.unet.parameters(), 'lr': 1e-4}\n",
    "        ], weight_decay=0.01)\n",
    "        \n",
    "        # 学习率scheduling器\n",
    "        self.scheduler_lr = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer, T_max=100, eta_min=1e-6\n",
    "        )\n",
    "        \n",
    "        # 混合精度training\n",
    "        self.scaler = GradScaler()\n",
    "        \n",
    "        # training参数\n",
    "        self.num_epochs = 50\n",
    "        self.batch_size = 8  # Colab GPU内存优化\n",
    "        self.gradient_accumulation_steps = 4\n",
    "        self.save_every = 5\n",
    "        \n",
    "        # 损失函数\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        \n",
    "        print(f\"✅ modelinitializationcomplete，using设备: {self.device}\")\n",
    "    \n",
    "    def create_synthetic_dataset(self, num_samples=1000):\n",
    "        \"\"\"\n",
    "        创建合成数据集用于演示\n",
    "        在实际使用中，这里应该加载真实的汉字数据\n",
    "        \"\"\"\n",
    "        print(f\"📊 create合成数据集 ({num_samples} 样本)...\")\n",
    "        \n",
    "        # create128x128of合成image\n",
    "        images = []\n",
    "        for i in range(num_samples):\n",
    "            # create简单of几何图案作为training数据\n",
    "            img = np.zeros((128, 128, 3), dtype=np.float32)\n",
    "            \n",
    "            # add一些随机几何形状\n",
    "            if i % 4 == 0:\n",
    "                # 圆形\n",
    "                y, x = np.ogrid[:128, :128]\n",
    "                mask = (x - 64)**2 + (y - 64)**2 <= 30**2\n",
    "                img[mask] = [0.8, 0.8, 0.8]\n",
    "            elif i % 4 == 1:\n",
    "                # 矩形\n",
    "                img[40:88, 40:88] = [0.7, 0.7, 0.7]\n",
    "            elif i % 4 == 2:\n",
    "                # 三角形\n",
    "                for y in range(128):\n",
    "                    for x in range(128):\n",
    "                        if y >= 64 and abs(x - 64) <= (y - 64):\n",
    "                            img[y, x] = [0.6, 0.6, 0.6]\n",
    "            else:\n",
    "                # 随机noise\n",
    "                img = np.random.rand(128, 128, 3).astype(np.float32) * 0.5\n",
    "            \n",
    "            # 归一化to[-1, 1]\n",
    "            img = (img - 0.5) * 2\n",
    "            images.append(img)\n",
    "        \n",
    "        # convert为tensor\n",
    "        images = torch.tensor(images, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "        print(f\"✅ 数据集createcomplete: {images.shape}\")\n",
    "        \n",
    "        return images\n",
    "    \n",
    "    def train_epoch(self, dataloader, epoch):\n",
    "        \"\"\"\n",
    "        训练一个epoch\n",
    "        \"\"\"\n",
    "        self.vae.train()\n",
    "        self.unet.train()\n",
    "        \n",
    "        total_loss = 0\n",
    "        num_batches = len(dataloader)\n",
    "        \n",
    "        for batch_idx, images in enumerate(dataloader):\n",
    "            images = images.to(self.device)\n",
    "            \n",
    "            # 梯度累积\n",
    "            with autocast():\n",
    "                # VAE编码\n",
    "                latents, mu, logvar, kl_loss = self.vae.encode(images)\n",
    "                \n",
    "                # addnoise\n",
    "                noise = torch.randn_like(latents)\n",
    "                timesteps = torch.randint(0, self.scheduler.num_train_timesteps, \n",
    "                                       (latents.shape[0],), device=self.device)\n",
    "                noisy_latents = self.scheduler.add_noise(latents, noise, timesteps)\n",
    "                \n",
    "                # UNetpredictionnoise\n",
    "                noise_pred = self.unet(noisy_latents, timesteps)\n",
    "                \n",
    "                # 计算损失\n",
    "                noise_loss = self.mse_loss(noise_pred, noise)\n",
    "                reconstruction_loss = self.mse_loss(self.vae.decode(latents), images)\n",
    "                \n",
    "                # 总损失\n",
    "                loss = noise_loss + 0.1 * kl_loss + 0.1 * reconstruction_loss\n",
    "                loss = loss / self.gradient_accumulation_steps\n",
    "            \n",
    "            # 反向传播\n",
    "            self.scaler.scale(loss).backward()\n",
    "            \n",
    "            if (batch_idx + 1) % self.gradient_accumulation_steps == 0:\n",
    "                # 梯度裁剪\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    list(self.vae.parameters()) + list(self.unet.parameters()), \n",
    "                    max_norm=1.0\n",
    "                )\n",
    "                \n",
    "                # 优化器步进\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "                self.optimizer.zero_grad()\n",
    "            \n",
    "            total_loss += loss.item() * self.gradient_accumulation_steps\n",
    "            \n",
    "            # 进度显示\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"   Epoch {epoch+1}/{self.num_epochs}, \"\n",
    "                      f\"Batch {batch_idx+1}/{num_batches}, \"\n",
    "                      f\"Loss: {loss.item():.6f}\")\n",
    "        \n",
    "        # 学习率scheduling\n",
    "        self.scheduler_lr.step()\n",
    "        \n",
    "        return total_loss / num_batches\n",
    "    \n",
    "    def save_checkpoint(self, epoch, loss, save_dir=\"colab_checkpoints\"):\n",
    "        \"\"\"\n",
    "        保存检查点\n",
    "        \"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'vae_state_dict': self.vae.state_dict(),\n",
    "            'unet_state_dict': self.unet.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler_lr.state_dict(),\n",
    "            'loss': loss,\n",
    "            'device': self.device\n",
    "        }\n",
    "        \n",
    "        checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"💾 check点已保存: {checkpoint_path}\")\n",
    "        \n",
    "        # 保存最佳model\n",
    "        if epoch == 0 or loss < getattr(self, 'best_loss', float('inf')):\n",
    "            self.best_loss = loss\n",
    "            best_model_path = os.path.join(save_dir, 'best_model.pth')\n",
    "            torch.save(checkpoint, best_model_path)\n",
    "            print(f\"🏆 最佳model已保存: {best_model_path}\")\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        主训练循环\n",
    "        \"\"\"\n",
    "        print(f\"\\n🎯 start training...\")\n",
    "        print(f\"   • 设备: {self.device}\")\n",
    "        print(f\"   • 批次大小: {self.batch_size}\")\n",
    "        print(f\"   • 梯度累积步数: {self.gradient_accumulation_steps}\")\n",
    "        print(f\"   • 总epochs: {self.num_epochs}\")\n",
    "        print(f\"   • 混合精度: {'启用' if self.device == 'cuda' else '禁用'}\")\n",
    "        \n",
    "        # create数据集\n",
    "        images = self.create_synthetic_dataset()\n",
    "        dataloader = DataLoader(images, batch_size=self.batch_size, shuffle=True)\n",
    "        \n",
    "        # training历史\n",
    "        train_losses = []\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            for epoch in range(self.num_epochs):\n",
    "                epoch_start = time.time()\n",
    "                \n",
    "                print(f\"\\n🔄 Epoch {epoch+1}/{self.num_epochs}\")\n",
    "                print(\"-\" * 50)\n",
    "                \n",
    "                # training\n",
    "                loss = self.train_epoch(dataloader, epoch)\n",
    "                train_losses.append(loss)\n",
    "                \n",
    "                epoch_time = time.time() - epoch_start\n",
    "                print(f\"   ⏱️  Epoch耗时: {epoch_time:.2f}秒\")\n",
    "                print(f\"   📊 平均损失: {loss:.6f}\")\n",
    "                print(f\"   📈 学习率: {self.optimizer.param_groups[0]['lr']:.2e}\")\n",
    "                \n",
    "                # 保存check点\n",
    "                if (epoch + 1) % self.save_every == 0:\n",
    "                    self.save_checkpoint(epoch, loss)\n",
    "                \n",
    "                # 内存清理 (Colab优化)\n",
    "                if self.device == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                \n",
    "                # 显示GPU内存using情况\n",
    "                if self.device == 'cuda':\n",
    "                    memory_allocated = torch.cuda.memory_allocated() / 1e9\n",
    "                    memory_reserved = torch.cuda.memory_reserved() / 1e9\n",
    "                    print(f\"   🧠 GPU内存: {memory_allocated:.2f}GB / {memory_reserved:.2f}GB\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\n⚠️  training被用户中断\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ training出错: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        finally:\n",
    "            # 保存最终model\n",
    "            final_loss = train_losses[-1] if train_losses else float('inf')\n",
    "            self.save_checkpoint(len(train_losses) - 1, final_loss)\n",
    "            \n",
    "            # training总结\n",
    "            total_time = time.time() - start_time\n",
    "            print(f\"\\n🎉 trainingcomplete!\")\n",
    "            print(f\"   ⏱️  总耗时: {total_time:.2f}秒\")\n",
    "            print(f\"   📊 最终损失: {final_loss:.6f}\")\n",
    "            print(f\"   📈 损失变化: {train_losses[0]:.6f} → {final_loss:.6f}\")\n",
    "            \n",
    "            # 绘制损失曲线\n",
    "            self.plot_training_curve(train_losses)\n",
    "    \n",
    "    def plot_training_curve(self, losses):\n",
    "        \"\"\"\n",
    "        绘制训练损失曲线\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(losses, 'b-', linewidth=2, label='训练损失')\n",
    "        plt.title('Colab训练损失曲线', fontsize=16)\n",
    "        plt.xlabel('Epoch', fontsize=14)\n",
    "        plt.ylabel('损失', fontsize=14)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend(fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # 保存图片\n",
    "        plot_path = 'colab_training_curve.png'\n",
    "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"📊 training曲线已保存: {plot_path}\")\n",
    "        plt.show()\n",
    "    \n",
    "    def test_generation(self, prompt=\"water\"):\n",
    "        \"\"\"\n",
    "        测试生成功能\n",
    "        \"\"\"\n",
    "        print(f\"\\n🧪 testgeneration: {prompt}\")\n",
    "        \n",
    "        try:\n",
    "            # createpipeline\n",
    "            pipeline = ImprovedStableDiffusionPipeline(device=self.device)\n",
    "            \n",
    "            # 加载training好ofweights\n",
    "            if hasattr(self, 'best_loss'):\n",
    "                checkpoint_path = 'colab_checkpoints/best_model.pth'\n",
    "                if os.path.exists(checkpoint_path):\n",
    "                    checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "                    pipeline.vae.load_state_dict(checkpoint['vae_state_dict'])\n",
    "                    pipeline.unet.load_state_dict(checkpoint['unet_state_dict'])\n",
    "                    print(f\"✅ 已加载最佳modelweights\")\n",
    "            \n",
    "            # generationimage\n",
    "            print(f\"🌊 generation中...\")\n",
    "            result = pipeline.generate(\n",
    "                prompt,\n",
    "                height=128,\n",
    "                width=128,\n",
    "                num_inference_steps=50,\n",
    "                guidance_scale=7.5,\n",
    "                seed=42\n",
    "            )\n",
    "            \n",
    "            # 保存结果\n",
    "            if isinstance(result, torch.Tensor):\n",
    "                result = (result + 1) / 2\n",
    "                result = torch.clamp(result, 0, 1)\n",
    "                img_array = result.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "                pil_image = Image.fromarray((img_array * 255).astype(np.uint8))\n",
    "            else:\n",
    "                pil_image = result\n",
    "            \n",
    "            output_path = f'colab_generated_{prompt}.png'\n",
    "            pil_image.save(output_path)\n",
    "            print(f\"✅ generationcomplete，已保存: {output_path}\")\n",
    "            \n",
    "            # 显示image\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(pil_image, cmap='gray')\n",
    "            plt.title(f'Colab生成: {prompt}', fontsize=14)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ generationtest失败: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    主函数\n",
    "    \"\"\"\n",
    "    print(\"🚀 Google Colab优化ofStable Diffusiontraining器\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # checkColab环境\n",
    "    is_colab = 'COLAB_GPU' in os.environ\n",
    "    if is_colab:\n",
    "        print(\"✅ 检测toGoogle Colab环境\")\n",
    "        print(f\"   • GPU类型: {os.environ.get('COLAB_GPU', 'Unknown')}\")\n",
    "        print(f\"   • run时类型: {os.environ.get('COLAB_RUNTIME_TYPE', 'Unknown')}\")\n",
    "    else:\n",
    "        print(\"💻 本地环境run\")\n",
    "    \n",
    "    # createtraining器\n",
    "    trainer = ColabOptimizedTrainer(device='auto')\n",
    "    \n",
    "    # start training\n",
    "    trainer.train()\n",
    "    \n",
    "    # testgeneration\n",
    "    trainer.test_generation(\"water\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}