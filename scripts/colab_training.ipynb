{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Google Colab\u4f18\u5316\u7684Stable Diffusion\u8bad\u7ec3\u811a\u672c\n",
        "\u4e13\u95e8\u4e3aColab GPU\u73af\u5883\u4f18\u5316\uff0c\u5305\u542b\u81ea\u52a8\u68c0\u6d4b\u548c\u6027\u80fd\u4f18\u5316\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gc\n",
        "\n",
        "# \u6dfb\u52a0\u5f53\u524d\u76ee\u5f55\u5230\u8def\u5f84\n",
        "sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
        "\n",
        "from improved_stable_diffusion import (\n",
        "    ImprovedStableDiffusionPipeline,\n",
        "    ImprovedVAE,\n",
        "    ImprovedUNet2DConditionModel,\n",
        "    ImprovedDDPMScheduler\n",
        ")\n",
        "\n",
        "class ColabOptimizedTrainer:\n",
        "    \"\"\"\n",
        "    Colab\u4f18\u5316\u7684\u8bad\u7ec3\u5668\n",
        "    \"\"\"\n",
        "    def __init__(self, device='auto'):\n",
        "        # \u81ea\u52a8\u68c0\u6d4b\u8bbe\u5907\n",
        "        if device == 'auto':\n",
        "            if torch.cuda.is_available():\n",
        "                self.device = 'cuda'\n",
        "                print(f\"\ud83d\ude80 \u68c0\u6d4b\u5230CUDA\u8bbe\u5907: {torch.cuda.get_device_name()}\")\n",
        "                print(f\"   \u2022 GPU\u5185\u5b58: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "                print(f\"   \u2022 CUDA\u7248\u672c: {torch.version.cuda}\")\n",
        "            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "                self.device = 'mps'\n",
        "                print(\"\ud83c\udf4e \u68c0\u6d4b\u5230Apple Silicon (MPS)\")\n",
        "            else:\n",
        "                self.device = 'cpu'\n",
        "                print(\"\ud83d\udcbb \u4f7f\u7528CPU\u8bad\u7ec3\")\n",
        "        else:\n",
        "            self.device = device\n",
        "        \n",
        "        # \u521d\u59cb\u5316\u6a21\u578b\n",
        "        self.vae = ImprovedVAE().to(self.device)\n",
        "        self.unet = ImprovedUNet2DConditionModel(\n",
        "            in_channels=4,\n",
        "            out_channels=4,\n",
        "            model_channels=128,\n",
        "            channel_mult=(1, 2, 4, 8),\n",
        "            attention_resolutions=(8, 16),\n",
        "            context_dim=512\n",
        "        ).to(self.device)\n",
        "        self.scheduler = ImprovedDDPMScheduler()\n",
        "        \n",
        "        # \u4f18\u5316\u5668\u8bbe\u7f6e\n",
        "        self.optimizer = optim.AdamW([\n",
        "            {'params': self.vae.parameters(), 'lr': 1e-4},\n",
        "            {'params': self.unet.parameters(), 'lr': 1e-4}\n",
        "        ], weight_decay=0.01)\n",
        "        \n",
        "        # \u5b66\u4e60\u7387\u8c03\u5ea6\u5668\n",
        "        self.scheduler_lr = optim.lr_scheduler.CosineAnnealingLR(\n",
        "            self.optimizer, T_max=100, eta_min=1e-6\n",
        "        )\n",
        "        \n",
        "        # \u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\n",
        "        self.scaler = GradScaler()\n",
        "        \n",
        "        # \u8bad\u7ec3\u53c2\u6570\n",
        "        self.num_epochs = 50\n",
        "        self.batch_size = 8  # Colab GPU\u5185\u5b58\u4f18\u5316\n",
        "        self.gradient_accumulation_steps = 4\n",
        "        self.save_every = 5\n",
        "        \n",
        "        # \u635f\u5931\u51fd\u6570\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        \n",
        "        print(f\"\u2705 \u6a21\u578b\u521d\u59cb\u5316\u5b8c\u6210\uff0c\u4f7f\u7528\u8bbe\u5907: {self.device}\")\n",
        "    \n",
        "    def create_synthetic_dataset(self, num_samples=1000):\n",
        "        \"\"\"\n",
        "        \u521b\u5efa\u5408\u6210\u6570\u636e\u96c6\u7528\u4e8e\u6f14\u793a\n",
        "        \u5728\u5b9e\u9645\u4f7f\u7528\u4e2d\uff0c\u8fd9\u91cc\u5e94\u8be5\u52a0\u8f7d\u771f\u5b9e\u7684\u6c49\u5b57\u6570\u636e\n",
        "        \"\"\"\n",
        "        print(f\"\ud83d\udcca \u521b\u5efa\u5408\u6210\u6570\u636e\u96c6 ({num_samples} \u6837\u672c)...\")\n",
        "        \n",
        "        # \u521b\u5efa128x128\u7684\u5408\u6210\u56fe\u50cf\n",
        "        images = []\n",
        "        for i in range(num_samples):\n",
        "            # \u521b\u5efa\u7b80\u5355\u7684\u51e0\u4f55\u56fe\u6848\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e\n",
        "            img = np.zeros((128, 128, 3), dtype=np.float32)\n",
        "            \n",
        "            # \u6dfb\u52a0\u4e00\u4e9b\u968f\u673a\u51e0\u4f55\u5f62\u72b6\n",
        "            if i % 4 == 0:\n",
        "                # \u5706\u5f62\n",
        "                y, x = np.ogrid[:128, :128]\n",
        "                mask = (x - 64)**2 + (y - 64)**2 <= 30**2\n",
        "                img[mask] = [0.8, 0.8, 0.8]\n",
        "            elif i % 4 == 1:\n",
        "                # \u77e9\u5f62\n",
        "                img[40:88, 40:88] = [0.7, 0.7, 0.7]\n",
        "            elif i % 4 == 2:\n",
        "                # \u4e09\u89d2\u5f62\n",
        "                for y in range(128):\n",
        "                    for x in range(128):\n",
        "                        if y >= 64 and abs(x - 64) <= (y - 64):\n",
        "                            img[y, x] = [0.6, 0.6, 0.6]\n",
        "            else:\n",
        "                # \u968f\u673a\u566a\u58f0\n",
        "                img = np.random.rand(128, 128, 3).astype(np.float32) * 0.5\n",
        "            \n",
        "            # \u5f52\u4e00\u5316\u5230[-1, 1]\n",
        "            img = (img - 0.5) * 2\n",
        "            images.append(img)\n",
        "        \n",
        "        # \u8f6c\u6362\u4e3atensor\n",
        "        images = torch.tensor(images, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "        print(f\"\u2705 \u6570\u636e\u96c6\u521b\u5efa\u5b8c\u6210: {images.shape}\")\n",
        "        \n",
        "        return images\n",
        "    \n",
        "    def train_epoch(self, dataloader, epoch):\n",
        "        \"\"\"\n",
        "        \u8bad\u7ec3\u4e00\u4e2aepoch\n",
        "        \"\"\"\n",
        "        self.vae.train()\n",
        "        self.unet.train()\n",
        "        \n",
        "        total_loss = 0\n",
        "        num_batches = len(dataloader)\n",
        "        \n",
        "        for batch_idx, images in enumerate(dataloader):\n",
        "            images = images.to(self.device)\n",
        "            \n",
        "            # \u68af\u5ea6\u7d2f\u79ef\n",
        "            with autocast():\n",
        "                # VAE\u7f16\u7801\n",
        "                latents, mu, logvar, kl_loss = self.vae.encode(images)\n",
        "                \n",
        "                # \u6dfb\u52a0\u566a\u58f0\n",
        "                noise = torch.randn_like(latents)\n",
        "                timesteps = torch.randint(0, self.scheduler.num_train_timesteps, \n",
        "                                       (latents.shape[0],), device=self.device)\n",
        "                noisy_latents = self.scheduler.add_noise(latents, noise, timesteps)\n",
        "                \n",
        "                # UNet\u9884\u6d4b\u566a\u58f0\n",
        "                noise_pred = self.unet(noisy_latents, timesteps)\n",
        "                \n",
        "                # \u8ba1\u7b97\u635f\u5931\n",
        "                noise_loss = self.mse_loss(noise_pred, noise)\n",
        "                reconstruction_loss = self.mse_loss(self.vae.decode(latents), images)\n",
        "                \n",
        "                # \u603b\u635f\u5931\n",
        "                loss = noise_loss + 0.1 * kl_loss + 0.1 * reconstruction_loss\n",
        "                loss = loss / self.gradient_accumulation_steps\n",
        "            \n",
        "            # \u53cd\u5411\u4f20\u64ad\n",
        "            self.scaler.scale(loss).backward()\n",
        "            \n",
        "            if (batch_idx + 1) % self.gradient_accumulation_steps == 0:\n",
        "                # \u68af\u5ea6\u88c1\u526a\n",
        "                self.scaler.unscale_(self.optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(\n",
        "                    list(self.vae.parameters()) + list(self.unet.parameters()), \n",
        "                    max_norm=1.0\n",
        "                )\n",
        "                \n",
        "                # \u4f18\u5316\u5668\u6b65\u8fdb\n",
        "                self.scaler.step(self.optimizer)\n",
        "                self.scaler.update()\n",
        "                self.optimizer.zero_grad()\n",
        "            \n",
        "            total_loss += loss.item() * self.gradient_accumulation_steps\n",
        "            \n",
        "            # \u8fdb\u5ea6\u663e\u793a\n",
        "            if (batch_idx + 1) % 10 == 0:\n",
        "                print(f\"   Epoch {epoch+1}/{self.num_epochs}, \"\n",
        "                      f\"Batch {batch_idx+1}/{num_batches}, \"\n",
        "                      f\"Loss: {loss.item():.6f}\")\n",
        "        \n",
        "        # \u5b66\u4e60\u7387\u8c03\u5ea6\n",
        "        self.scheduler_lr.step()\n",
        "        \n",
        "        return total_loss / num_batches\n",
        "    \n",
        "    def save_checkpoint(self, epoch, loss, save_dir=\"colab_checkpoints\"):\n",
        "        \"\"\"\n",
        "        \u4fdd\u5b58\u68c0\u67e5\u70b9\n",
        "        \"\"\"\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        \n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'vae_state_dict': self.vae.state_dict(),\n",
        "            'unet_state_dict': self.unet.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'scheduler_state_dict': self.scheduler_lr.state_dict(),\n",
        "            'loss': loss,\n",
        "            'device': self.device\n",
        "        }\n",
        "        \n",
        "        checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
        "        torch.save(checkpoint, checkpoint_path)\n",
        "        print(f\"\ud83d\udcbe \u68c0\u67e5\u70b9\u5df2\u4fdd\u5b58: {checkpoint_path}\")\n",
        "        \n",
        "        # \u4fdd\u5b58\u6700\u4f73\u6a21\u578b\n",
        "        if epoch == 0 or loss < getattr(self, 'best_loss', float('inf')):\n",
        "            self.best_loss = loss\n",
        "            best_model_path = os.path.join(save_dir, 'best_model.pth')\n",
        "            torch.save(checkpoint, best_model_path)\n",
        "            print(f\"\ud83c\udfc6 \u6700\u4f73\u6a21\u578b\u5df2\u4fdd\u5b58: {best_model_path}\")\n",
        "    \n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        \u4e3b\u8bad\u7ec3\u5faa\u73af\n",
        "        \"\"\"\n",
        "        print(f\"\\n\ud83c\udfaf \u5f00\u59cb\u8bad\u7ec3...\")\n",
        "        print(f\"   \u2022 \u8bbe\u5907: {self.device}\")\n",
        "        print(f\"   \u2022 \u6279\u6b21\u5927\u5c0f: {self.batch_size}\")\n",
        "        print(f\"   \u2022 \u68af\u5ea6\u7d2f\u79ef\u6b65\u6570: {self.gradient_accumulation_steps}\")\n",
        "        print(f\"   \u2022 \u603bepochs: {self.num_epochs}\")\n",
        "        print(f\"   \u2022 \u6df7\u5408\u7cbe\u5ea6: {'\u542f\u7528' if self.device == 'cuda' else '\u7981\u7528'}\")\n",
        "        \n",
        "        # \u521b\u5efa\u6570\u636e\u96c6\n",
        "        images = self.create_synthetic_dataset()\n",
        "        dataloader = DataLoader(images, batch_size=self.batch_size, shuffle=True)\n",
        "        \n",
        "        # \u8bad\u7ec3\u5386\u53f2\n",
        "        train_losses = []\n",
        "        start_time = time.time()\n",
        "        \n",
        "        try:\n",
        "            for epoch in range(self.num_epochs):\n",
        "                epoch_start = time.time()\n",
        "                \n",
        "                print(f\"\\n\ud83d\udd04 Epoch {epoch+1}/{self.num_epochs}\")\n",
        "                print(\"-\" * 50)\n",
        "                \n",
        "                # \u8bad\u7ec3\n",
        "                loss = self.train_epoch(dataloader, epoch)\n",
        "                train_losses.append(loss)\n",
        "                \n",
        "                epoch_time = time.time() - epoch_start\n",
        "                print(f\"   \u23f1\ufe0f  Epoch\u8017\u65f6: {epoch_time:.2f}\u79d2\")\n",
        "                print(f\"   \ud83d\udcca \u5e73\u5747\u635f\u5931: {loss:.6f}\")\n",
        "                print(f\"   \ud83d\udcc8 \u5b66\u4e60\u7387: {self.optimizer.param_groups[0]['lr']:.2e}\")\n",
        "                \n",
        "                # \u4fdd\u5b58\u68c0\u67e5\u70b9\n",
        "                if (epoch + 1) % self.save_every == 0:\n",
        "                    self.save_checkpoint(epoch, loss)\n",
        "                \n",
        "                # \u5185\u5b58\u6e05\u7406 (Colab\u4f18\u5316)\n",
        "                if self.device == 'cuda':\n",
        "                    torch.cuda.empty_cache()\n",
        "                    gc.collect()\n",
        "                \n",
        "                # \u663e\u793aGPU\u5185\u5b58\u4f7f\u7528\u60c5\u51b5\n",
        "                if self.device == 'cuda':\n",
        "                    memory_allocated = torch.cuda.memory_allocated() / 1e9\n",
        "                    memory_reserved = torch.cuda.memory_reserved() / 1e9\n",
        "                    print(f\"   \ud83e\udde0 GPU\u5185\u5b58: {memory_allocated:.2f}GB / {memory_reserved:.2f}GB\")\n",
        "        \n",
        "        except KeyboardInterrupt:\n",
        "            print(f\"\\n\u26a0\ufe0f  \u8bad\u7ec3\u88ab\u7528\u6237\u4e2d\u65ad\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\n\u274c \u8bad\u7ec3\u51fa\u9519: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "        \n",
        "        finally:\n",
        "            # \u4fdd\u5b58\u6700\u7ec8\u6a21\u578b\n",
        "            final_loss = train_losses[-1] if train_losses else float('inf')\n",
        "            self.save_checkpoint(len(train_losses) - 1, final_loss)\n",
        "            \n",
        "            # \u8bad\u7ec3\u603b\u7ed3\n",
        "            total_time = time.time() - start_time\n",
        "            print(f\"\\n\ud83c\udf89 \u8bad\u7ec3\u5b8c\u6210!\")\n",
        "            print(f\"   \u23f1\ufe0f  \u603b\u8017\u65f6: {total_time:.2f}\u79d2\")\n",
        "            print(f\"   \ud83d\udcca \u6700\u7ec8\u635f\u5931: {final_loss:.6f}\")\n",
        "            print(f\"   \ud83d\udcc8 \u635f\u5931\u53d8\u5316: {train_losses[0]:.6f} \u2192 {final_loss:.6f}\")\n",
        "            \n",
        "            # \u7ed8\u5236\u635f\u5931\u66f2\u7ebf\n",
        "            self.plot_training_curve(train_losses)\n",
        "    \n",
        "    def plot_training_curve(self, losses):\n",
        "        \"\"\"\n",
        "        \u7ed8\u5236\u8bad\u7ec3\u635f\u5931\u66f2\u7ebf\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(losses, 'b-', linewidth=2, label='\u8bad\u7ec3\u635f\u5931')\n",
        "        plt.title('Colab\u8bad\u7ec3\u635f\u5931\u66f2\u7ebf', fontsize=16)\n",
        "        plt.xlabel('Epoch', fontsize=14)\n",
        "        plt.ylabel('\u635f\u5931', fontsize=14)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.legend(fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # \u4fdd\u5b58\u56fe\u7247\n",
        "        plot_path = 'colab_training_curve.png'\n",
        "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"\ud83d\udcca \u8bad\u7ec3\u66f2\u7ebf\u5df2\u4fdd\u5b58: {plot_path}\")\n",
        "        plt.show()\n",
        "    \n",
        "    def test_generation(self, prompt=\"water\"):\n",
        "        \"\"\"\n",
        "        \u6d4b\u8bd5\u751f\u6210\u529f\u80fd\n",
        "        \"\"\"\n",
        "        print(f\"\\n\ud83e\uddea \u6d4b\u8bd5\u751f\u6210: {prompt}\")\n",
        "        \n",
        "        try:\n",
        "            # \u521b\u5efapipeline\n",
        "            pipeline = ImprovedStableDiffusionPipeline(device=self.device)\n",
        "            \n",
        "            # \u52a0\u8f7d\u8bad\u7ec3\u597d\u7684\u6743\u91cd\n",
        "            if hasattr(self, 'best_loss'):\n",
        "                checkpoint_path = 'colab_checkpoints/best_model.pth'\n",
        "                if os.path.exists(checkpoint_path):\n",
        "                    checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
        "                    pipeline.vae.load_state_dict(checkpoint['vae_state_dict'])\n",
        "                    pipeline.unet.load_state_dict(checkpoint['unet_state_dict'])\n",
        "                    print(f\"\u2705 \u5df2\u52a0\u8f7d\u6700\u4f73\u6a21\u578b\u6743\u91cd\")\n",
        "            \n",
        "            # \u751f\u6210\u56fe\u50cf\n",
        "            print(f\"\ud83c\udf0a \u751f\u6210\u4e2d...\")\n",
        "            result = pipeline.generate(\n",
        "                prompt,\n",
        "                height=128,\n",
        "                width=128,\n",
        "                num_inference_steps=50,\n",
        "                guidance_scale=7.5,\n",
        "                seed=42\n",
        "            )\n",
        "            \n",
        "            # \u4fdd\u5b58\u7ed3\u679c\n",
        "            if isinstance(result, torch.Tensor):\n",
        "                result = (result + 1) / 2\n",
        "                result = torch.clamp(result, 0, 1)\n",
        "                img_array = result.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
        "                pil_image = Image.fromarray((img_array * 255).astype(np.uint8))\n",
        "            else:\n",
        "                pil_image = result\n",
        "            \n",
        "            output_path = f'colab_generated_{prompt}.png'\n",
        "            pil_image.save(output_path)\n",
        "            print(f\"\u2705 \u751f\u6210\u5b8c\u6210\uff0c\u5df2\u4fdd\u5b58: {output_path}\")\n",
        "            \n",
        "            # \u663e\u793a\u56fe\u50cf\n",
        "            plt.figure(figsize=(6, 6))\n",
        "            plt.imshow(pil_image, cmap='gray')\n",
        "            plt.title(f'Colab\u751f\u6210: {prompt}', fontsize=14)\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"\u274c \u751f\u6210\u6d4b\u8bd5\u5931\u8d25: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    \u4e3b\u51fd\u6570\n",
        "    \"\"\"\n",
        "    print(\"\ud83d\ude80 Google Colab\u4f18\u5316\u7684Stable Diffusion\u8bad\u7ec3\u5668\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # \u68c0\u67e5Colab\u73af\u5883\n",
        "    is_colab = 'COLAB_GPU' in os.environ\n",
        "    if is_colab:\n",
        "        print(\"\u2705 \u68c0\u6d4b\u5230Google Colab\u73af\u5883\")\n",
        "        print(f\"   \u2022 GPU\u7c7b\u578b: {os.environ.get('COLAB_GPU', 'Unknown')}\")\n",
        "        print(f\"   \u2022 \u8fd0\u884c\u65f6\u7c7b\u578b: {os.environ.get('COLAB_RUNTIME_TYPE', 'Unknown')}\")\n",
        "    else:\n",
        "        print(\"\ud83d\udcbb \u672c\u5730\u73af\u5883\u8fd0\u884c\")\n",
        "    \n",
        "    # \u521b\u5efa\u8bad\u7ec3\u5668\n",
        "    trainer = ColabOptimizedTrainer(device='auto')\n",
        "    \n",
        "    # \u5f00\u59cb\u8bad\u7ec3\n",
        "    trainer.train()\n",
        "    \n",
        "    # \u6d4b\u8bd5\u751f\u6210\n",
        "    trainer.test_generation(\"water\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}