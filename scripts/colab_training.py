#!/usr/bin/env python3
"""
Google Colabä¼˜åŒ–çš„Stable Diffusionè®­ç»ƒè„šæœ¬
ä¸“é—¨ä¸ºColab GPUç¯å¢ƒä¼˜åŒ–ï¼ŒåŒ…å«è‡ªåŠ¨æ£€æµ‹å’Œæ€§èƒ½ä¼˜åŒ–
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torch.nn.functional as F
from torch.cuda.amp import GradScaler, autocast
import os
import sys
import time
from pathlib import Path
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import gc

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from improved_stable_diffusion import (
    ImprovedStableDiffusionPipeline,
    ImprovedVAE,
    ImprovedUNet2DConditionModel,
    ImprovedDDPMScheduler
)

class ColabOptimizedTrainer:
    """
    Colabä¼˜åŒ–çš„è®­ç»ƒå™¨
    """
    def __init__(self, device='auto'):
        # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
        if device == 'auto':
            if torch.cuda.is_available():
                self.device = 'cuda'
                print(f"ğŸš€ æ£€æµ‹åˆ°CUDAè®¾å¤‡: {torch.cuda.get_device_name()}")
                print(f"   â€¢ GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
                print(f"   â€¢ CUDAç‰ˆæœ¬: {torch.version.cuda}")
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                self.device = 'mps'
                print("ğŸ æ£€æµ‹åˆ°Apple Silicon (MPS)")
            else:
                self.device = 'cpu'
                print("ğŸ’» ä½¿ç”¨CPUè®­ç»ƒ")
        else:
            self.device = device
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.vae = ImprovedVAE().to(self.device)
        self.unet = ImprovedUNet2DConditionModel(
            in_channels=4,
            out_channels=4,
            model_channels=128,
            channel_mult=(1, 2, 4, 8),
            attention_resolutions=(8, 16),
            context_dim=512
        ).to(self.device)
        self.scheduler = ImprovedDDPMScheduler()
        
        # ä¼˜åŒ–å™¨è®¾ç½®
        self.optimizer = optim.AdamW([
            {'params': self.vae.parameters(), 'lr': 1e-4},
            {'params': self.unet.parameters(), 'lr': 1e-4}
        ], weight_decay=0.01)
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler_lr = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer, T_max=100, eta_min=1e-6
        )
        
        # æ··åˆç²¾åº¦è®­ç»ƒ
        self.scaler = GradScaler()
        
        # è®­ç»ƒå‚æ•°
        self.num_epochs = 50
        self.batch_size = 8  # Colab GPUå†…å­˜ä¼˜åŒ–
        self.gradient_accumulation_steps = 4
        self.save_every = 5
        
        # æŸå¤±å‡½æ•°
        self.mse_loss = nn.MSELoss()
        
        print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def create_synthetic_dataset(self, num_samples=1000):
        """
        åˆ›å»ºåˆæˆæ•°æ®é›†ç”¨äºæ¼”ç¤º
        åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥åŠ è½½çœŸå®çš„æ±‰å­—æ•°æ®
        """
        print(f"ğŸ“Š åˆ›å»ºåˆæˆæ•°æ®é›† ({num_samples} æ ·æœ¬)...")
        
        # åˆ›å»º128x128çš„åˆæˆå›¾åƒ
        images = []
        for i in range(num_samples):
            # åˆ›å»ºç®€å•çš„å‡ ä½•å›¾æ¡ˆä½œä¸ºè®­ç»ƒæ•°æ®
            img = np.zeros((128, 128, 3), dtype=np.float32)
            
            # æ·»åŠ ä¸€äº›éšæœºå‡ ä½•å½¢çŠ¶
            if i % 4 == 0:
                # åœ†å½¢
                y, x = np.ogrid[:128, :128]
                mask = (x - 64)**2 + (y - 64)**2 <= 30**2
                img[mask] = [0.8, 0.8, 0.8]
            elif i % 4 == 1:
                # çŸ©å½¢
                img[40:88, 40:88] = [0.7, 0.7, 0.7]
            elif i % 4 == 2:
                # ä¸‰è§’å½¢
                for y in range(128):
                    for x in range(128):
                        if y >= 64 and abs(x - 64) <= (y - 64):
                            img[y, x] = [0.6, 0.6, 0.6]
            else:
                # éšæœºå™ªå£°
                img = np.random.rand(128, 128, 3).astype(np.float32) * 0.5
            
            # å½’ä¸€åŒ–åˆ°[-1, 1]
            img = (img - 0.5) * 2
            images.append(img)
        
        # è½¬æ¢ä¸ºtensor
        images = torch.tensor(images, dtype=torch.float32).permute(0, 3, 1, 2)
        print(f"âœ… æ•°æ®é›†åˆ›å»ºå®Œæˆ: {images.shape}")
        
        return images
    
    def train_epoch(self, dataloader, epoch):
        """
        è®­ç»ƒä¸€ä¸ªepoch
        """
        self.vae.train()
        self.unet.train()
        
        total_loss = 0
        num_batches = len(dataloader)
        
        for batch_idx, images in enumerate(dataloader):
            images = images.to(self.device)
            
            # æ¢¯åº¦ç´¯ç§¯
            with autocast():
                # VAEç¼–ç 
                latents, mu, logvar, kl_loss = self.vae.encode(images)
                
                # æ·»åŠ å™ªå£°
                noise = torch.randn_like(latents)
                timesteps = torch.randint(0, self.scheduler.num_train_timesteps, 
                                       (latents.shape[0],), device=self.device)
                noisy_latents = self.scheduler.add_noise(latents, noise, timesteps)
                
                # UNeté¢„æµ‹å™ªå£°
                noise_pred = self.unet(noisy_latents, timesteps)
                
                # è®¡ç®—æŸå¤±
                noise_loss = self.mse_loss(noise_pred, noise)
                reconstruction_loss = self.mse_loss(self.vae.decode(latents), images)
                
                # æ€»æŸå¤±
                loss = noise_loss + 0.1 * kl_loss + 0.1 * reconstruction_loss
                loss = loss / self.gradient_accumulation_steps
            
            # åå‘ä¼ æ’­
            self.scaler.scale(loss).backward()
            
            if (batch_idx + 1) % self.gradient_accumulation_steps == 0:
                # æ¢¯åº¦è£å‰ª
                self.scaler.unscale_(self.optimizer)
                torch.nn.utils.clip_grad_norm_(
                    list(self.vae.parameters()) + list(self.unet.parameters()), 
                    max_norm=1.0
                )
                
                # ä¼˜åŒ–å™¨æ­¥è¿›
                self.scaler.step(self.optimizer)
                self.scaler.update()
                self.optimizer.zero_grad()
            
            total_loss += loss.item() * self.gradient_accumulation_steps
            
            # è¿›åº¦æ˜¾ç¤º
            if (batch_idx + 1) % 10 == 0:
                print(f"   Epoch {epoch+1}/{self.num_epochs}, "
                      f"Batch {batch_idx+1}/{num_batches}, "
                      f"Loss: {loss.item():.6f}")
        
        # å­¦ä¹ ç‡è°ƒåº¦
        self.scheduler_lr.step()
        
        return total_loss / num_batches
    
    def save_checkpoint(self, epoch, loss, save_dir="colab_checkpoints"):
        """
        ä¿å­˜æ£€æŸ¥ç‚¹
        """
        os.makedirs(save_dir, exist_ok=True)
        
        checkpoint = {
            'epoch': epoch,
            'vae_state_dict': self.vae.state_dict(),
            'unet_state_dict': self.unet.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler_lr.state_dict(),
            'loss': loss,
            'device': self.device
        }
        
        checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}.pth')
        torch.save(checkpoint, checkpoint_path)
        print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if epoch == 0 or loss < getattr(self, 'best_loss', float('inf')):
            self.best_loss = loss
            best_model_path = os.path.join(save_dir, 'best_model.pth')
            torch.save(checkpoint, best_model_path)
            print(f"ğŸ† æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {best_model_path}")
    
    def train(self):
        """
        ä¸»è®­ç»ƒå¾ªç¯
        """
        print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
        print(f"   â€¢ è®¾å¤‡: {self.device}")
        print(f"   â€¢ æ‰¹æ¬¡å¤§å°: {self.batch_size}")
        print(f"   â€¢ æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: {self.gradient_accumulation_steps}")
        print(f"   â€¢ æ€»epochs: {self.num_epochs}")
        print(f"   â€¢ æ··åˆç²¾åº¦: {'å¯ç”¨' if self.device == 'cuda' else 'ç¦ç”¨'}")
        
        # åˆ›å»ºæ•°æ®é›†
        images = self.create_synthetic_dataset()
        dataloader = DataLoader(images, batch_size=self.batch_size, shuffle=True)
        
        # è®­ç»ƒå†å²
        train_losses = []
        start_time = time.time()
        
        try:
            for epoch in range(self.num_epochs):
                epoch_start = time.time()
                
                print(f"\nğŸ”„ Epoch {epoch+1}/{self.num_epochs}")
                print("-" * 50)
                
                # è®­ç»ƒ
                loss = self.train_epoch(dataloader, epoch)
                train_losses.append(loss)
                
                epoch_time = time.time() - epoch_start
                print(f"   â±ï¸  Epochè€—æ—¶: {epoch_time:.2f}ç§’")
                print(f"   ğŸ“Š å¹³å‡æŸå¤±: {loss:.6f}")
                print(f"   ğŸ“ˆ å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.2e}")
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                if (epoch + 1) % self.save_every == 0:
                    self.save_checkpoint(epoch, loss)
                
                # å†…å­˜æ¸…ç† (Colabä¼˜åŒ–)
                if self.device == 'cuda':
                    torch.cuda.empty_cache()
                    gc.collect()
                
                # æ˜¾ç¤ºGPUå†…å­˜ä½¿ç”¨æƒ…å†µ
                if self.device == 'cuda':
                    memory_allocated = torch.cuda.memory_allocated() / 1e9
                    memory_reserved = torch.cuda.memory_reserved() / 1e9
                    print(f"   ğŸ§  GPUå†…å­˜: {memory_allocated:.2f}GB / {memory_reserved:.2f}GB")
        
        except KeyboardInterrupt:
            print(f"\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"\nâŒ è®­ç»ƒå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
        
        finally:
            # ä¿å­˜æœ€ç»ˆæ¨¡å‹
            final_loss = train_losses[-1] if train_losses else float('inf')
            self.save_checkpoint(len(train_losses) - 1, final_loss)
            
            # è®­ç»ƒæ€»ç»“
            total_time = time.time() - start_time
            print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
            print(f"   â±ï¸  æ€»è€—æ—¶: {total_time:.2f}ç§’")
            print(f"   ğŸ“Š æœ€ç»ˆæŸå¤±: {final_loss:.6f}")
            print(f"   ğŸ“ˆ æŸå¤±å˜åŒ–: {train_losses[0]:.6f} â†’ {final_loss:.6f}")
            
            # ç»˜åˆ¶æŸå¤±æ›²çº¿
            self.plot_training_curve(train_losses)
    
    def plot_training_curve(self, losses):
        """
        ç»˜åˆ¶è®­ç»ƒæŸå¤±æ›²çº¿
        """
        plt.figure(figsize=(10, 6))
        plt.plot(losses, 'b-', linewidth=2, label='è®­ç»ƒæŸå¤±')
        plt.title('Colabè®­ç»ƒæŸå¤±æ›²çº¿', fontsize=16)
        plt.xlabel('Epoch', fontsize=14)
        plt.ylabel('æŸå¤±', fontsize=14)
        plt.grid(True, alpha=0.3)
        plt.legend(fontsize=12)
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        plot_path = 'colab_training_curve.png'
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        print(f"ğŸ“Š è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {plot_path}")
        plt.show()
    
    def test_generation(self, prompt="water"):
        """
        æµ‹è¯•ç”ŸæˆåŠŸèƒ½
        """
        print(f"\nğŸ§ª æµ‹è¯•ç”Ÿæˆ: {prompt}")
        
        try:
            # åˆ›å»ºpipeline
            pipeline = ImprovedStableDiffusionPipeline(device=self.device)
            
            # åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
            if hasattr(self, 'best_loss'):
                checkpoint_path = 'colab_checkpoints/best_model.pth'
                if os.path.exists(checkpoint_path):
                    checkpoint = torch.load(checkpoint_path, map_location=self.device)
                    pipeline.vae.load_state_dict(checkpoint['vae_state_dict'])
                    pipeline.unet.load_state_dict(checkpoint['unet_state_dict'])
                    print(f"âœ… å·²åŠ è½½æœ€ä½³æ¨¡å‹æƒé‡")
            
            # ç”Ÿæˆå›¾åƒ
            print(f"ğŸŒŠ ç”Ÿæˆä¸­...")
            result = pipeline.generate(
                prompt,
                height=128,
                width=128,
                num_inference_steps=50,
                guidance_scale=7.5,
                seed=42
            )
            
            # ä¿å­˜ç»“æœ
            if isinstance(result, torch.Tensor):
                result = (result + 1) / 2
                result = torch.clamp(result, 0, 1)
                img_array = result.squeeze(0).permute(1, 2, 0).cpu().numpy()
                pil_image = Image.fromarray((img_array * 255).astype(np.uint8))
            else:
                pil_image = result
            
            output_path = f'colab_generated_{prompt}.png'
            pil_image.save(output_path)
            print(f"âœ… ç”Ÿæˆå®Œæˆï¼Œå·²ä¿å­˜: {output_path}")
            
            # æ˜¾ç¤ºå›¾åƒ
            plt.figure(figsize=(6, 6))
            plt.imshow(pil_image, cmap='gray')
            plt.title(f'Colabç”Ÿæˆ: {prompt}', fontsize=14)
            plt.axis('off')
            plt.show()
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

def main():
    """
    ä¸»å‡½æ•°
    """
    print("ğŸš€ Google Colabä¼˜åŒ–çš„Stable Diffusionè®­ç»ƒå™¨")
    print("=" * 60)
    
    # æ£€æŸ¥Colabç¯å¢ƒ
    is_colab = 'COLAB_GPU' in os.environ
    if is_colab:
        print("âœ… æ£€æµ‹åˆ°Google Colabç¯å¢ƒ")
        print(f"   â€¢ GPUç±»å‹: {os.environ.get('COLAB_GPU', 'Unknown')}")
        print(f"   â€¢ è¿è¡Œæ—¶ç±»å‹: {os.environ.get('COLAB_RUNTIME_TYPE', 'Unknown')}")
    else:
        print("ğŸ’» æœ¬åœ°ç¯å¢ƒè¿è¡Œ")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = ColabOptimizedTrainer(device='auto')
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train()
    
    # æµ‹è¯•ç”Ÿæˆ
    trainer.test_generation("water")

if __name__ == "__main__":
    main()
