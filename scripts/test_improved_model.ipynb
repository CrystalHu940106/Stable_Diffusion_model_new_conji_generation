{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "\u6d4b\u8bd5\u6539\u8fdb\u540e\u7684Stable Diffusion\u6a21\u578b\n",
        "\u6bd4\u8f83\u6539\u8fdb\u524d\u540e\u7684\u6027\u80fd\u5dee\u5f02\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
        "\n",
        "from stable_diffusion_kanji import StableDiffusionPipeline as OriginalPipeline\n",
        "from improved_stable_diffusion import ImprovedStableDiffusionPipeline as ImprovedPipeline\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def test_model_comparison():\n",
        "    \"\"\"\u6bd4\u8f83\u539f\u59cb\u6a21\u578b\u548c\u6539\u8fdb\u6a21\u578b\u7684\u6027\u80fd\"\"\"\n",
        "    \n",
        "    print(\"\ud83c\udf8c \u6a21\u578b\u6027\u80fd\u5bf9\u6bd4\u6d4b\u8bd5\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"\ud83d\udd27 \u4f7f\u7528\u8bbe\u5907: {device}\")\n",
        "    \n",
        "    # \u6d4b\u8bd5\u6982\u5ff5\n",
        "    concepts = [\"water\", \"future\"]\n",
        "    \n",
        "    # \u6d4b\u8bd5\u539f\u59cb\u6a21\u578b\n",
        "    print(f\"\\n\ud83d\udd0d \u6d4b\u8bd5\u539f\u59cb\u6a21\u578b...\")\n",
        "    try:\n",
        "        original_pipeline = OriginalPipeline(device=device)\n",
        "        print(\"\u2705 \u539f\u59cb\u6a21\u578b\u521d\u59cb\u5316\u6210\u529f\")\n",
        "        \n",
        "        for concept in concepts:\n",
        "            print(f\"\\n\ud83c\udf0a \u539f\u59cb\u6a21\u578b\u751f\u6210 '{concept}'...\")\n",
        "            start_time = time.time()\n",
        "            \n",
        "            try:\n",
        "                result = original_pipeline.generate(\n",
        "                    concept,\n",
        "                    height=128,\n",
        "                    width=128,\n",
        "                    num_inference_steps=50,\n",
        "                    guidance_scale=12.0,\n",
        "                    seed=42\n",
        "                )\n",
        "                \n",
        "                generation_time = time.time() - start_time\n",
        "                print(f\"   \u23f1\ufe0f  \u751f\u6210\u65f6\u95f4: {generation_time:.2f}\u79d2\")\n",
        "                \n",
        "                # \u8f6c\u6362\u4e3aPIL\u56fe\u50cf\n",
        "                if isinstance(result, torch.Tensor):\n",
        "                    result = (result + 1) / 2\n",
        "                    result = torch.clamp(result, 0, 1)\n",
        "                    img_array = result.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
        "                    pil_image = Image.fromarray((img_array * 255).astype(np.uint8))\n",
        "                else:\n",
        "                    pil_image = result\n",
        "                \n",
        "                # \u4fdd\u5b58\u7ed3\u679c\n",
        "                output_path = f\"original_{concept}.png\"\n",
        "                pil_image.save(output_path)\n",
        "                print(f\"   \ud83d\udcbe \u5df2\u4fdd\u5b58: {output_path}\")\n",
        "                \n",
        "                # \u5206\u6790\u56fe\u50cf\u8d28\u91cf\n",
        "                img_array = np.array(pil_image.convert('L'))\n",
        "                print(f\"   \ud83d\udcca \u56fe\u50cf\u7edf\u8ba1:\")\n",
        "                print(f\"      \u2022 \u5c3a\u5bf8: {img_array.shape}\")\n",
        "                print(f\"      \u2022 \u6700\u5c0f\u503c: {img_array.min()}\")\n",
        "                print(f\"      \u2022 \u6700\u5927\u503c: {img_array.max()}\")\n",
        "                print(f\"      \u2022 \u5e73\u5747\u503c: {img_array.mean():.2f}\")\n",
        "                print(f\"      \u2022 \u6807\u51c6\u5dee: {img_array.std():.2f}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"   \u274c \u751f\u6210\u5931\u8d25: {e}\")\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"\u274c \u539f\u59cb\u6a21\u578b\u521d\u59cb\u5316\u5931\u8d25: {e}\")\n",
        "    \n",
        "    # \u6d4b\u8bd5\u6539\u8fdb\u6a21\u578b\n",
        "    print(f\"\\n\ud83d\udd0d \u6d4b\u8bd5\u6539\u8fdb\u6a21\u578b...\")\n",
        "    try:\n",
        "        improved_pipeline = ImprovedPipeline(device=device)\n",
        "        print(\"\u2705 \u6539\u8fdb\u6a21\u578b\u521d\u59cb\u5316\u6210\u529f\")\n",
        "        \n",
        "        for concept in concepts:\n",
        "            print(f\"\\n\ud83c\udf0a \u6539\u8fdb\u6a21\u578b\u751f\u6210 '{concept}'...\")\n",
        "            start_time = time.time()\n",
        "            \n",
        "            try:\n",
        "                result = improved_pipeline.generate(\n",
        "                    concept,\n",
        "                    height=128,\n",
        "                    width=128,\n",
        "                    num_inference_steps=50,\n",
        "                    guidance_scale=7.5,  # \u4f7f\u7528\u5b98\u65b9\u63a8\u8350\u7684guidance scale\n",
        "                    seed=42\n",
        "                )\n",
        "                \n",
        "                generation_time = time.time() - start_time\n",
        "                print(f\"   \u23f1\ufe0f  \u751f\u6210\u65f6\u95f4: {generation_time:.2f}\u79d2\")\n",
        "                \n",
        "                # \u8f6c\u6362\u4e3aPIL\u56fe\u50cf\n",
        "                if isinstance(result, torch.Tensor):\n",
        "                    result = (result + 1) / 2\n",
        "                    result = torch.clamp(result, 0, 1)\n",
        "                    img_array = result.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
        "                    pil_image = Image.fromarray((img_array * 255).astype(np.uint8))\n",
        "                else:\n",
        "                    pil_image = result\n",
        "                \n",
        "                # \u4fdd\u5b58\u7ed3\u679c\n",
        "                output_path = f\"improved_{concept}.png\"\n",
        "                pil_image.save(output_path)\n",
        "                print(f\"   \ud83d\udcbe \u5df2\u4fdd\u5b58: {output_path}\")\n",
        "                \n",
        "                # \u5206\u6790\u56fe\u50cf\u8d28\u91cf\n",
        "                img_array = np.array(pil_image.convert('L'))\n",
        "                print(f\"   \ud83d\udcca \u56fe\u50cf\u7edf\u8ba1:\")\n",
        "                print(f\"      \u2022 \u5c3a\u5bf8: {img_array.shape}\")\n",
        "                print(f\"      \u2022 \u6700\u5c0f\u503c: {img_array.min()}\")\n",
        "                print(f\"      \u2022 \u6700\u5927\u503c: {img_array.max()}\")\n",
        "                print(f\"      \u2022 \u5e73\u5747\u503c: {img_array.mean():.2f}\")\n",
        "                print(f\"      \u2022 \u6807\u51c6\u5dee: {img_array.std():.2f}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"   \u274c \u751f\u6210\u5931\u8d25: {e}\")\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"\u274c \u6539\u8fdb\u6a21\u578b\u521d\u59cb\u5316\u5931\u8d25: {e}\")\n",
        "    \n",
        "    # \u751f\u6210\u5bf9\u6bd4\u56fe\n",
        "    print(f\"\\n\ud83c\udfa8 \u751f\u6210\u5bf9\u6bd4\u56fe...\")\n",
        "    try:\n",
        "        concepts = [\"water\", \"future\"]\n",
        "        fig, axes = plt.subplots(len(concepts), 2, figsize=(12, 10))\n",
        "        \n",
        "        for i, concept in enumerate(concepts):\n",
        "            # \u539f\u59cb\u6a21\u578b\u7ed3\u679c\n",
        "            original_file = f\"original_{concept}.png\"\n",
        "            if os.path.exists(original_file):\n",
        "                original_img = Image.open(original_file)\n",
        "                axes[i, 0].imshow(original_img, cmap='gray')\n",
        "                axes[i, 0].set_title(f'{concept} - \u539f\u59cb\u6a21\u578b')\n",
        "                axes[i, 0].axis('off')\n",
        "            else:\n",
        "                axes[i, 0].text(0.5, 0.5, f'{concept}\\n\u539f\u59cb\u6a21\u578b\\n\u751f\u6210\u5931\u8d25', \n",
        "                              ha='center', va='center', transform=axes[i, 0].transAxes)\n",
        "                axes[i, 0].set_title(f'{concept} - \u539f\u59cb\u6a21\u578b')\n",
        "                axes[i, 0].axis('off')\n",
        "            \n",
        "            # \u6539\u8fdb\u6a21\u578b\u7ed3\u679c\n",
        "            improved_file = f\"improved_{concept}.png\"\n",
        "            if os.path.exists(improved_file):\n",
        "                improved_img = Image.open(improved_file)\n",
        "                axes[i, 1].imshow(improved_img, cmap='gray')\n",
        "                axes[i, 1].set_title(f'{concept} - \u6539\u8fdb\u6a21\u578b')\n",
        "                axes[i, 1].axis('off')\n",
        "            else:\n",
        "                axes[i, 1].text(0.5, 0.5, f'{concept}\\n\u6539\u8fdb\u6a21\u578b\\n\u751f\u6210\u5931\u8d25', \n",
        "                              ha='center', va='center', transform=axes[i, 1].transAxes)\n",
        "                axes[i, 1].set_title(f'{concept} - \u6539\u8fdb\u6a21\u578b')\n",
        "                axes[i, 1].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        comparison_path = 'model_comparison.png'\n",
        "        plt.savefig(comparison_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"\u2705 \u5bf9\u6bd4\u56fe\u5df2\u4fdd\u5b58: {comparison_path}\")\n",
        "        plt.show()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u274c \u751f\u6210\u5bf9\u6bd4\u56fe\u5931\u8d25: {e}\")\n",
        "    \n",
        "    print(f\"\\n\ud83c\udf89 \u6a21\u578b\u5bf9\u6bd4\u6d4b\u8bd5\u5b8c\u6210\uff01\")\n",
        "    print(f\"\ud83d\udcc1 \u751f\u6210\u7684\u6587\u4ef6:\")\n",
        "    for concept in concepts:\n",
        "        print(f\"   \u2022 original_{concept}.png - \u539f\u59cb\u6a21\u578b\u7ed3\u679c\")\n",
        "        print(f\"   \u2022 improved_{concept}.png - \u6539\u8fdb\u6a21\u578b\u7ed3\u679c\")\n",
        "    print(f\"   \u2022 model_comparison.png - \u5bf9\u6bd4\u56fe\")\n",
        "\n",
        "def analyze_improvements():\n",
        "    \"\"\"\u5206\u6790\u6539\u8fdb\u70b9\"\"\"\n",
        "    \n",
        "    print(f\"\\n\ud83d\udd0d \u6539\u8fdb\u70b9\u5206\u6790\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    improvements = [\n",
        "        \"\ud83c\udfd7\ufe0f  \u67b6\u6784\u6539\u8fdb:\",\n",
        "        \"   \u2022 \u4f7f\u7528GroupNorm\u66ff\u4ee3BatchNorm\uff0c\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\",\n",
        "        \"   \u2022 \u4f7f\u7528SiLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u66ff\u4ee3LeakyReLU\",\n",
        "        \"   \u2022 \u66f4\u6df1\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u589e\u52a0\u6a21\u578b\u5bb9\u91cf\",\n",
        "        \"\",\n",
        "        \"\ud83c\udfaf \u8bad\u7ec3\u7b56\u7565\u6539\u8fdb:\",\n",
        "        \"   \u2022 \u501f\u9274\u5b98\u65b9\u7684\u65f6\u95f4\u5d4c\u5165\u7f51\u7edc\u8bbe\u8ba1\",\n",
        "        \"   \u2022 \u6539\u8fdb\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\",\n",
        "        \"   \u2022 \u66f4\u597d\u7684\u6b8b\u5dee\u5757\u8bbe\u8ba1\",\n",
        "        \"\",\n",
        "        \"\u2699\ufe0f  \u63a8\u7406\u4f18\u5316:\",\n",
        "        \"   \u2022 \u4f7f\u7528\u5b98\u65b9\u63a8\u8350\u7684guidance scale (7.5)\",\n",
        "        \"   \u2022 \u6539\u8fdb\u7684DDPM\u8c03\u5ea6\u5668\",\n",
        "        \"   \u2022 \u66f4\u7a33\u5b9a\u7684\u53bb\u566a\u8fc7\u7a0b\",\n",
        "        \"\",\n",
        "        \"\ud83d\udcdd \u63d0\u793a\u5de5\u7a0b:\",\n",
        "        \"   \u2022 \u66f4\u8be6\u7ec6\u7684\u6c49\u5b57\u63cf\u8ff0\",\n",
        "        \"   \u2022 \u4e13\u4e1a\u8d28\u91cf\u7684\u827a\u672f\u98ce\u683c\u63cf\u8ff0\",\n",
        "        \"   \u2022 \u5f3a\u8c03\u5bf9\u6bd4\u5ea6\u548c\u6e05\u6670\u5ea6\"\n",
        "    ]\n",
        "    \n",
        "    for improvement in improvements:\n",
        "        print(improvement)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_model_comparison()\n",
        "    analyze_improvements()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}