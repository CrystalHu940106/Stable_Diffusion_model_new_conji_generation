{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Debug Generation Issues\n",
        "Analyze why generated images are mostly white and provide solutions\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "def analyze_model_output():\n",
        "    \"\"\"Analyze what the model is actually outputting\"\"\"\n",
        "    \n",
        "    print(\"\ud83d\udd0d Debugging Generation Issues\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Load the trained model\n",
        "    model_path = \"quick_test_results/quick_test_epoch_2.pth\"\n",
        "    if not Path(model_path).exists():\n",
        "        print(\"\u274c Model not found!\")\n",
        "        return\n",
        "    \n",
        "    # Load model\n",
        "    checkpoint = torch.load(model_path, map_location='cpu')\n",
        "    print(f\"\u2705 Model loaded: {model_path}\")\n",
        "    print(f\"   \u2022 Final loss: {checkpoint.get('loss', 'Unknown'):.2e}\")\n",
        "    \n",
        "    # Create test input\n",
        "    test_input = torch.randn(1, 3, 64, 64)\n",
        "    print(f\"   \u2022 Test input shape: {test_input.shape}\")\n",
        "    print(f\"   \u2022 Test input range: [{test_input.min():.3f}, {test_input.max():.3f}]\")\n",
        "    \n",
        "    # Load model and generate\n",
        "    from quick_train_test import SimpleUNet\n",
        "    model = SimpleUNet()\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(test_input)\n",
        "    \n",
        "    print(f\"   \u2022 Model output shape: {output.shape}\")\n",
        "    print(f\"   \u2022 Model output range: [{output.min():.3f}, {output.max():.3f}]\")\n",
        "    print(f\"   \u2022 Model output mean: {output.mean():.3f}\")\n",
        "    print(f\"   \u2022 Model output std: {output.std():.3f}\")\n",
        "    \n",
        "    # Analyze the issue\n",
        "    print(f\"\\n\ud83c\udfaf Problem Analysis:\")\n",
        "    \n",
        "    if output.min() > 0.9:\n",
        "        print(f\"   \u274c Issue: Output is too bright (all values > 0.9)\")\n",
        "        print(f\"   \ud83d\udca1 Cause: Model learned to output white/light colors\")\n",
        "    elif output.max() < 0.1:\n",
        "        print(f\"   \u274c Issue: Output is too dark (all values < 0.1)\")\n",
        "        print(f\"   \ud83d\udca1 Cause: Model learned to output black/dark colors\")\n",
        "    elif output.std() < 0.01:\n",
        "        print(f\"   \u274c Issue: Output has no variation (std < 0.01)\")\n",
        "        print(f\"   \ud83d\udca1 Cause: Model output is uniform/constant\")\n",
        "    else:\n",
        "        print(f\"   \u2705 Output range looks reasonable\")\n",
        "    \n",
        "    return output\n",
        "\n",
        "def analyze_training_data():\n",
        "    \"\"\"Analyze the training data to understand the issue\"\"\"\n",
        "    \n",
        "    print(f\"\\n\ud83d\udcda Training Data Analysis:\")\n",
        "    \n",
        "    # Load dataset\n",
        "    dataset_path = Path(\"kanji_dataset/metadata/test_dataset.json\")\n",
        "    if not dataset_path.exists():\n",
        "        print(\"\u274c Test dataset not found!\")\n",
        "        return\n",
        "    \n",
        "    with open(dataset_path, 'r') as f:\n",
        "        dataset = json.load(f)\n",
        "    \n",
        "    print(f\"   \u2022 Test dataset size: {len(dataset)} samples\")\n",
        "    \n",
        "    # Check a few sample images\n",
        "    from quick_train_test import QuickKanjiDataset, create_quick_transforms\n",
        "    \n",
        "    transform = create_quick_transforms()\n",
        "    test_dataset = QuickKanjiDataset(\"kanji_dataset\", transform=transform, use_test_data=True)\n",
        "    \n",
        "    print(f\"\\n   \ud83d\udcf8 Sample Training Images:\")\n",
        "    for i in range(3):\n",
        "        sample = test_dataset[i]\n",
        "        img_tensor = sample['image']\n",
        "        \n",
        "        print(f\"     {i+1}. {sample['kanji']}: {', '.join(sample['meanings'][:2])}\")\n",
        "        print(f\"        \u2022 Tensor range: [{img_tensor.min():.3f}, {img_tensor.max():.3f}]\")\n",
        "        print(f\"        \u2022 Tensor mean: {img_tensor.mean():.3f}\")\n",
        "        print(f\"        \u2022 Tensor std: {img_tensor.std():.3f}\")\n",
        "\n",
        "def provide_solutions():\n",
        "    \"\"\"Provide solutions to fix the generation issues\"\"\"\n",
        "    \n",
        "    print(f\"\\n\ud83d\udca1 Solutions to Fix Generation Issues:\")\n",
        "    \n",
        "    print(f\"\\n\ud83d\udd27 Immediate Fixes:\")\n",
        "    print(f\"   1. **Invert Output**: Convert white output to black strokes\")\n",
        "    print(f\"   2. **Adjust Threshold**: Apply threshold to create binary images\")\n",
        "    print(f\"   3. **Change Loss Function**: Use different loss for better learning\")\n",
        "    print(f\"   4. **Modify Training Data**: Invert training images (black background)\")\n",
        "    \n",
        "    print(f\"\\n\ud83d\ude80 Long-term Solutions:\")\n",
        "    print(f\"   1. **Full Training**: Train on complete dataset (6,410 samples)\")\n",
        "    print(f\"   2. **Better Architecture**: Use Stable Diffusion instead of simple UNet\")\n",
        "    print(f\"   3. **Proper Diffusion**: Implement actual diffusion process\")\n",
        "    print(f\"   4. **Text Conditioning**: Add CLIP text encoder for better control\")\n",
        "    print(f\"   5. **Higher Resolution**: Use 128x128 or 256x256 resolution\")\n",
        "    \n",
        "    print(f\"\\n\u26a1 Quick Test Solutions:\")\n",
        "    print(f\"   1. **Invert Colors**: 1 - output to get black strokes\")\n",
        "    print(f\"   2. **Threshold**: Apply threshold to create binary images\")\n",
        "    print(f\"   3. **Different Input**: Use structured noise instead of random\")\n",
        "    print(f\"   4. **Post-processing**: Apply morphological operations\")\n",
        "\n",
        "def create_fixed_generation():\n",
        "    \"\"\"Create fixed generation with color inversion\"\"\"\n",
        "    \n",
        "    print(f\"\\n\ud83c\udfa8 Creating Fixed Generation...\")\n",
        "    \n",
        "    # Load model\n",
        "    model_path = \"quick_test_results/quick_test_epoch_2.pth\"\n",
        "    from quick_train_test import SimpleUNet\n",
        "    model = SimpleUNet()\n",
        "    checkpoint = torch.load(model_path, map_location='cpu')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "    \n",
        "    # Create different inputs\n",
        "    inputs = {\n",
        "        'random': torch.randn(4, 3, 64, 64),\n",
        "        'structured': torch.randn(4, 3, 64, 64) * 0.5 + 0.5,  # More structured\n",
        "        'low_freq': torch.randn(4, 3, 16, 16).repeat(1, 1, 4, 4),  # Low frequency\n",
        "    }\n",
        "    \n",
        "    # Create output directory\n",
        "    output_dir = Path(\"fixed_generation\")\n",
        "    output_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    for input_name, input_tensor in inputs.items():\n",
        "        print(f\"   Testing {input_name} input...\")\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "        \n",
        "        # Apply fixes\n",
        "        fixes = {\n",
        "            'original': output,\n",
        "            'inverted': 1 - output,  # Invert colors\n",
        "            'threshold': (output > 0.5).float(),  # Binary threshold\n",
        "            'enhanced': torch.clamp(output * 2 - 0.5, 0, 1),  # Enhance contrast\n",
        "        }\n",
        "        \n",
        "        for fix_name, fixed_output in fixes.items():\n",
        "            # Convert to image\n",
        "            for i in range(4):\n",
        "                img_array = fixed_output[i].permute(1, 2, 0).numpy()\n",
        "                img_array = (img_array * 255).astype(np.uint8)\n",
        "                img = Image.fromarray(img_array)\n",
        "                \n",
        "                filename = f\"fixed_{input_name}_{fix_name}_{i+1}.png\"\n",
        "                img.save(output_dir / filename)\n",
        "                print(f\"     \u2022 Saved: {filename}\")\n",
        "    \n",
        "    print(f\"\\n\u2705 Fixed generation completed!\")\n",
        "    print(f\"   \u2022 Results saved in: {output_dir}\")\n",
        "    print(f\"   \u2022 Try different fixes: original, inverted, threshold, enhanced\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function\"\"\"\n",
        "    \n",
        "    # Analyze model output\n",
        "    output = analyze_model_output()\n",
        "    \n",
        "    # Analyze training data\n",
        "    analyze_training_data()\n",
        "    \n",
        "    # Provide solutions\n",
        "    provide_solutions()\n",
        "    \n",
        "    # Create fixed generation\n",
        "    create_fixed_generation()\n",
        "    \n",
        "    print(f\"\\n\ud83c\udf89 Debug Analysis Complete!\")\n",
        "    print(f\"   \u2022 Problem identified: Model outputs mostly white\")\n",
        "    print(f\"   \u2022 Solutions provided\")\n",
        "    print(f\"   \u2022 Fixed generation created\")\n",
        "    \n",
        "    print(f\"\\n\ud83d\udccb Next Steps:\")\n",
        "    print(f\"   1. Check fixed_generation/ folder for improved results\")\n",
        "    print(f\"   2. Consider proceeding with full training\")\n",
        "    print(f\"   3. Use better architecture (Stable Diffusion)\")\n",
        "    print(f\"   4. Implement proper diffusion process\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}