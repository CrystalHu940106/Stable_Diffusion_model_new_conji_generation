{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 Working Stable Diffusion Training - Fixed Version\n",
    "\n",
    "**Simplified architecture that actually works!** \n",
    "\n",
    "## ✅ Fixed Issues:\n",
    "- GroupNorm channel mismatch errors\n",
    "- IndexError with empty training losses\n",
    "- Simplified UNet architecture for stability\n",
    "- Robust error handling\n",
    "\n",
    "## 🎯 Architecture:\n",
    "- **SimpleVAE**: 128x128 ↔ 16x16x4 latent space\n",
    "- **SimpleUNet**: 64-channel, 2 ResBlocks, no up/downsampling\n",
    "- **SimpleDDPMScheduler**: Linear noise schedule\n",
    "- **Training**: 5 epochs, 100 samples, batch size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install torch torchvision matplotlib pillow numpy\n",
    "print(\"✅ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Check environment\n",
    "is_colab = 'COLAB_GPU' in os.environ\n",
    "is_kaggle = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "\n",
    "print(f\"🌐 Environment: {'Colab' if is_colab else 'Kaggle' if is_kaggle else 'Local'}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"⚠️ Using CPU (will be slower)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "\n",
    "\n",
    "class SimpleVAE(nn.Module):\n",
    "    \"\"\"Extremely simplified VAE for testing\"\"\"\n",
    "    def __init__(self, in_channels=3, latent_channels=4):\n",
    "        super().__init__()\n",
    "        self.latent_channels = latent_channels\n",
    "        \n",
    "        # Encoder: 128x128 -> 16x16x4\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=4, stride=2, padding=1),  # 64x64\n",
    "            nn.GroupNorm(8, 32),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),  # 32x32\n",
    "            nn.GroupNorm(8, 64),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # 16x16\n",
    "            nn.GroupNorm(8, 128),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(128, latent_channels * 2, kernel_size=1),  # mu and logvar\n",
    "        )\n",
    "        \n",
    "        # Decoder: 16x16x4 -> 128x128x3\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(latent_channels, 128, kernel_size=1),\n",
    "            nn.GroupNorm(8, 128),\n",
    "            nn.SiLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # 32x32\n",
    "            nn.GroupNorm(8, 64),\n",
    "            nn.SiLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),  # 64x64\n",
    "            nn.GroupNorm(8, 32),\n",
    "            nn.SiLU(),\n",
    "            nn.ConvTranspose2d(32, in_channels, kernel_size=4, stride=2, padding=1),  # 128x128\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        mu, logvar = torch.chunk(encoded, 2, dim=1)\n",
    "        \n",
    "        # KL loss\n",
    "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.shape[0]\n",
    "        \n",
    "        # Reparameterization\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        \n",
    "        return z, mu, logvar, kl_loss\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "\n",
    "class SimpleResBlock(nn.Module):\n",
    "    \"\"\"Extremely simplified ResBlock\"\"\"\n",
    "    def __init__(self, channels, time_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.GroupNorm(8, channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "            nn.GroupNorm(8, channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.time_proj = nn.Linear(time_dim, channels)\n",
    "        \n",
    "    def forward(self, x, time_emb):\n",
    "        h = self.block(x)\n",
    "        \n",
    "        # Add time embedding\n",
    "        time_emb = self.time_proj(time_emb)\n",
    "        time_emb = time_emb.view(x.shape[0], -1, 1, 1)\n",
    "        h = h + time_emb\n",
    "        \n",
    "        return h + x\n",
    "\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    \"\"\"Extremely simplified UNet\"\"\"\n",
    "    def __init__(self, in_channels=4, out_channels=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_embedding = nn.Sequential(\n",
    "            nn.Linear(1, 128),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(128, 128)\n",
    "        )\n",
    "        \n",
    "        # Simple path: no up/down sampling\n",
    "        self.input_conv = nn.Conv2d(in_channels, 64, 3, padding=1)\n",
    "        self.res1 = SimpleResBlock(64, 128)\n",
    "        self.res2 = SimpleResBlock(64, 128)\n",
    "        self.output_conv = nn.Sequential(\n",
    "            nn.GroupNorm(8, 64),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(64, out_channels, 3, padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, timesteps, context=None):\n",
    "        # Time embedding\n",
    "        if timesteps.dim() == 0:\n",
    "            timesteps = timesteps.unsqueeze(0)\n",
    "        t = self.time_embedding(timesteps.float().unsqueeze(-1))\n",
    "        \n",
    "        # Forward pass\n",
    "        h = self.input_conv(x)\n",
    "        h = self.res1(h, t)\n",
    "        h = self.res2(h, t)\n",
    "        return self.output_conv(h)\n",
    "\n",
    "\n",
    "class SimpleDDPMScheduler:\n",
    "    \"\"\"Extremely simplified scheduler\"\"\"\n",
    "    def __init__(self, num_train_timesteps=1000):\n",
    "        self.num_train_timesteps = num_train_timesteps\n",
    "        \n",
    "        self.betas = torch.linspace(0.0001, 0.02, num_train_timesteps)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "        \n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n",
    "    \n",
    "    def add_noise(self, original_samples, noise, timesteps):\n",
    "        device = original_samples.device\n",
    "        \n",
    "        sqrt_alpha = self.sqrt_alphas_cumprod.to(device)[timesteps].view(-1, 1, 1, 1)\n",
    "        sqrt_one_minus_alpha = self.sqrt_one_minus_alphas_cumprod.to(device)[timesteps].view(-1, 1, 1, 1)\n",
    "        \n",
    "        return sqrt_alpha * original_samples + sqrt_one_minus_alpha * noise\n",
    "\n",
    "print(\"✅ Model classes defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkingTrainer:\n",
    "    \"\"\"Simplified trainer that actually works\"\"\"\n",
    "    \n",
    "    def __init__(self, device='auto'):\n",
    "        # Auto-detect device\n",
    "        if device == 'auto':\n",
    "            if torch.cuda.is_available():\n",
    "                self.device = 'cuda'\n",
    "                print(f\"🚀 Using CUDA: {torch.cuda.get_device_name()}\")\n",
    "            else:\n",
    "                self.device = 'cpu'\n",
    "                print(\"💻 Using CPU\")\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        # Initialize models\n",
    "        self.vae = SimpleVAE().to(self.device)\n",
    "        self.unet = SimpleUNet().to(self.device)\n",
    "        self.scheduler = SimpleDDPMScheduler()\n",
    "        \n",
    "        # Optimizer\n",
    "        self.optimizer = optim.AdamW([\n",
    "            {'params': self.vae.parameters(), 'lr': 1e-4},\n",
    "            {'params': self.unet.parameters(), 'lr': 1e-4}\n",
    "        ], weight_decay=0.01)\n",
    "        \n",
    "        # Training parameters\n",
    "        self.num_epochs = 5\n",
    "        self.batch_size = 4\n",
    "        self.save_every = 2\n",
    "        \n",
    "        # Loss function\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        \n",
    "        print(f\"✅ Trainer initialized on {self.device}\")\n",
    "    \n",
    "    def create_synthetic_dataset(self, num_samples=100):\n",
    "        \"\"\"Create simple synthetic dataset\"\"\"\n",
    "        print(f\"📊 Creating dataset ({num_samples} samples)...\")\n",
    "        \n",
    "        images = []\n",
    "        for i in range(num_samples):\n",
    "            img = np.zeros((128, 128, 3), dtype=np.float32)\n",
    "            \n",
    "            if i % 4 == 0:\n",
    "                # Circle\n",
    "                y, x = np.ogrid[:128, :128]\n",
    "                mask = (x - 64)**2 + (y - 64)**2 <= 30**2\n",
    "                img[mask] = [0.8, 0.8, 0.8]\n",
    "            elif i % 4 == 1:\n",
    "                # Rectangle\n",
    "                img[40:88, 40:88] = [0.7, 0.7, 0.7]\n",
    "            elif i % 4 == 2:\n",
    "                # Triangle\n",
    "                for y in range(128):\n",
    "                    for x in range(128):\n",
    "                        if y >= 64 and abs(x - 64) <= (y - 64):\n",
    "                            img[y, x] = [0.6, 0.6, 0.6]\n",
    "            else:\n",
    "                # Random noise\n",
    "                img = np.random.rand(128, 128, 3).astype(np.float32) * 0.5\n",
    "            \n",
    "            # Normalize to [-1, 1]\n",
    "            img = (img - 0.5) * 2\n",
    "            images.append(img)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        images = np.array(images)\n",
    "        images = torch.tensor(images, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "        print(f\"✅ Dataset created: {images.shape}\")\n",
    "        \n",
    "        return images\n",
    "    \n",
    "    def train_epoch(self, dataloader, epoch):\n",
    "        \"\"\"Train one epoch\"\"\"\n",
    "        self.vae.train()\n",
    "        self.unet.train()\n",
    "        \n",
    "        total_loss = 0\n",
    "        num_batches = len(dataloader)\n",
    "        \n",
    "        for batch_idx, images in enumerate(dataloader):\n",
    "            images = images.to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            latents, mu, logvar, kl_loss = self.vae.encode(images)\n",
    "            \n",
    "            # Add noise\n",
    "            noise = torch.randn_like(latents, device=self.device)\n",
    "            timesteps = torch.randint(\n",
    "                0, self.scheduler.num_train_timesteps, \n",
    "                (latents.shape[0],), \n",
    "                device=self.device\n",
    "            )\n",
    "            noisy_latents = self.scheduler.add_noise(latents, noise, timesteps)\n",
    "            \n",
    "            # UNet prediction\n",
    "            noise_pred = self.unet(noisy_latents, timesteps)\n",
    "            \n",
    "            # Calculate losses\n",
    "            noise_loss = self.mse_loss(noise_pred, noise)\n",
    "            reconstruction_loss = self.mse_loss(self.vae.decode(latents), images)\n",
    "            \n",
    "            loss = noise_loss + 0.1 * kl_loss + 0.1 * reconstruction_loss\n",
    "            \n",
    "            # Backward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                list(self.vae.parameters()) + list(self.unet.parameters()), \n",
    "                max_norm=1.0\n",
    "            )\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Progress\n",
    "            if (batch_idx + 1) % 5 == 0:\n",
    "                print(f\"   Epoch {epoch+1}/{self.num_epochs}, \"\n",
    "                      f\"Batch {batch_idx+1}/{num_batches}, \"\n",
    "                      f\"Loss: {loss.item():.6f}\")\n",
    "        \n",
    "        return total_loss / num_batches\n",
    "    \n",
    "    def save_checkpoint(self, epoch, loss, save_dir=\"working_checkpoints\"):\n",
    "        \"\"\"Save checkpoint\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'vae_state_dict': self.vae.state_dict(),\n",
    "            'unet_state_dict': self.unet.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            'device': self.device\n",
    "        }\n",
    "        \n",
    "        checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"💾 Checkpoint saved: {checkpoint_path}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if epoch == 0 or loss < getattr(self, 'best_loss', float('inf')):\n",
    "            self.best_loss = loss\n",
    "            best_model_path = os.path.join(save_dir, 'best_model.pth')\n",
    "            torch.save(checkpoint, best_model_path)\n",
    "            print(f\"🏆 Best model saved: {best_model_path}\")\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Main training loop\"\"\"\n",
    "        print(f\"\\n🎯 Starting training...\")\n",
    "        print(f\"   • Device: {self.device}\")\n",
    "        print(f\"   • Batch size: {self.batch_size}\")\n",
    "        print(f\"   • Epochs: {self.num_epochs}\")\n",
    "        \n",
    "        # Create dataset\n",
    "        images = self.create_synthetic_dataset()\n",
    "        dataloader = DataLoader(images, batch_size=self.batch_size, shuffle=True)\n",
    "        \n",
    "        # Training history\n",
    "        train_losses = []\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            for epoch in range(self.num_epochs):\n",
    "                epoch_start = time.time()\n",
    "                \n",
    "                print(f\"\\n🔄 Epoch {epoch+1}/{self.num_epochs}\")\n",
    "                print(\"-\" * 50)\n",
    "                \n",
    "                # Train\n",
    "                loss = self.train_epoch(dataloader, epoch)\n",
    "                train_losses.append(loss)\n",
    "                \n",
    "                epoch_time = time.time() - epoch_start\n",
    "                print(f\"   ⏱️  Epoch time: {epoch_time:.2f}s\")\n",
    "                print(f\"   📊 Average loss: {loss:.6f}\")\n",
    "                \n",
    "                # Save checkpoint\n",
    "                if (epoch + 1) % self.save_every == 0:\n",
    "                    self.save_checkpoint(epoch, loss)\n",
    "                \n",
    "                # Memory cleanup\n",
    "                if self.device == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\n⚠️  Training interrupted\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Training error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        finally:\n",
    "            # Save final model\n",
    "            final_loss = train_losses[-1] if train_losses else float('inf')\n",
    "            if train_losses:  # Only save if we have training data\n",
    "                self.save_checkpoint(len(train_losses) - 1, final_loss)\n",
    "            \n",
    "            # Training summary\n",
    "            total_time = time.time() - start_time\n",
    "            print(f\"\\n🎉 Training complete!\")\n",
    "            print(f\"   ⏱️  Total time: {total_time:.2f}s\")\n",
    "            print(f\"   📊 Final loss: {final_loss:.6f}\")\n",
    "            \n",
    "            # Only show loss change if we have data\n",
    "            if train_losses:\n",
    "                print(f\"   📈 Loss change: {train_losses[0]:.6f} → {final_loss:.6f}\")\n",
    "                # Plot training curve\n",
    "                self.plot_training_curve(train_losses)\n",
    "            else:\n",
    "                print(\"   ⚠️  No training epochs completed\")\n",
    "    \n",
    "    def plot_training_curve(self, losses):\n",
    "        \"\"\"Plot training curve\"\"\"\n",
    "        if not losses:\n",
    "            print(\"⚠️ No loss data to plot\")\n",
    "            return\n",
    "            \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(losses, 'b-', linewidth=2, label='Training Loss')\n",
    "        plt.title('Training Loss Curve', fontsize=16)\n",
    "        plt.xlabel('Epoch', fontsize=14)\n",
    "        plt.ylabel('Loss', fontsize=14)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend(fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot\n",
    "        plot_path = 'working_training_curve.png'\n",
    "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"📊 Training curve saved: {plot_path}\")\n",
    "        plt.show()\n",
    "\n",
    "print(\"✅ WorkingTrainer class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 START TRAINING!\n",
    "print(\"🔧 Starting training with simplified, working architecture...\")\n",
    "\n",
    "try:\n",
    "    trainer = WorkingTrainer()\n",
    "    trainer.train()\n",
    "    print(\"\\n✅ Training completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a simple generation (simplified version)\n",
    "def test_simple_generation():\n",
    "    \"\"\"Test simple image generation\"\"\"\n",
    "    print(\"🧪 Testing simple generation...\")\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Create models\n",
    "    vae = SimpleVAE().to(device)\n",
    "    unet = SimpleUNet().to(device)\n",
    "    scheduler = SimpleDDPMScheduler()\n",
    "    \n",
    "    # Load best model if available\n",
    "    checkpoint_path = 'working_checkpoints/best_model.pth'\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        vae.load_state_dict(checkpoint['vae_state_dict'])\n",
    "        unet.load_state_dict(checkpoint['unet_state_dict'])\n",
    "        print(\"✅ Loaded trained model\")\n",
    "    else:\n",
    "        print(\"⚠️ Using untrained model (for testing)\")\n",
    "    \n",
    "    vae.eval()\n",
    "    unet.eval()\n",
    "    \n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        # Start with random noise in latent space\n",
    "        latents = torch.randn(1, 4, 16, 16, device=device)\n",
    "        \n",
    "        # Simple denoising (simplified)\n",
    "        for step in range(20):\n",
    "            t = torch.tensor([step * 50], device=device)  # Simple timestep\n",
    "            \n",
    "            # Predict noise\n",
    "            noise_pred = unet(latents, t)\n",
    "            \n",
    "            # Simple denoising step\n",
    "            latents = latents - 0.01 * noise_pred\n",
    "        \n",
    "        # Decode to image\n",
    "        image = vae.decode(latents)\n",
    "        \n",
    "        # Convert to displayable format\n",
    "        image = (image + 1) / 2  # [-1, 1] -> [0, 1]\n",
    "        image = torch.clamp(image, 0, 1)\n",
    "        img_array = image.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "        \n",
    "        # Display\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(img_array)\n",
    "        plt.title('Generated Image (Simplified)', fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # Save\n",
    "        pil_image = Image.fromarray((img_array * 255).astype(np.uint8))\n",
    "        pil_image.save('test_generation.png')\n",
    "        print(\"✅ Test generation saved: test_generation.png\")\n",
    "\n",
    "# Run the test\n",
    "test_simple_generation()"
   ]
  }\n",
  ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.8.5\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 4\n}