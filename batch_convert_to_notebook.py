#!/usr/bin/env python3
"""
æ‰¹é‡è½¬æ¢Pythonè„šæœ¬ä¸ºJupyter notebook
æ‰«ææ•´ä¸ªé¡¹ç›®åŒ…ï¼Œç”Ÿæˆèƒ½åœ¨Colabå’ŒKaggleä¸Šè¿è¡Œçš„notebook
"""

import os
import subprocess
import sys
from pathlib import Path

def batch_convert_to_notebooks():
    """æ‰¹é‡è½¬æ¢Pythonæ–‡ä»¶ä¸ºJupyter notebook"""
    
    # æ‰«æscriptsç›®å½•
    scripts_dir = './scripts'
    
    if not os.path.exists(scripts_dir):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {scripts_dir}")
        return
    
    print(f"ğŸ” æ‰«æç›®å½•: {scripts_dir}")
    
    # é‡ç‚¹è½¬æ¢çš„è®­ç»ƒç›¸å…³è„šæœ¬
    priority_files = [
        'colab_training.py',
        'train_stable_diffusion.py', 
        'improved_stable_diffusion.py',
        'test_improved_model.py'
    ]
    
    converted_files = []
    
    # é¦–å…ˆè½¬æ¢ä¼˜å…ˆçº§æ–‡ä»¶
    for filename in priority_files:
        py_path = os.path.join(scripts_dir, filename)
        if os.path.exists(py_path):
            ipynb_path = py_path.replace('.py', '.ipynb')
            
            print(f"ğŸ”„ è½¬æ¢: {filename}")
            try:
                # ä½¿ç”¨ipynb-py-convertè½¬æ¢
                result = subprocess.run([
                    '/Users/hu.crystal/Library/Python/3.9/bin/ipynb-py-convert', 
                    py_path, ipynb_path
                ], capture_output=True, text=True)
                
                if result.returncode == 0:
                    print(f"âœ… æˆåŠŸè½¬æ¢: {ipynb_path}")
                    converted_files.append(ipynb_path)
                else:
                    print(f"âŒ è½¬æ¢å¤±è´¥: {filename}")
                    print(f"é”™è¯¯: {result.stderr}")
                    
            except Exception as e:
                print(f"âŒ è½¬æ¢é”™è¯¯ {filename}: {e}")
    
    # ç„¶åè½¬æ¢å…¶ä»–Pythonæ–‡ä»¶
    for filename in os.listdir(scripts_dir):
        if filename.endswith('.py') and filename not in priority_files:
            py_path = os.path.join(scripts_dir, filename)
            ipynb_path = py_path.replace('.py', '.ipynb')
            
            print(f"ğŸ”„ è½¬æ¢: {filename}")
            try:
                result = subprocess.run([
                    '/Users/hu.crystal/Library/Python/3.9/bin/ipynb-py-convert', 
                    py_path, ipynb_path
                ], capture_output=True, text=True)
                
                if result.returncode == 0:
                    print(f"âœ… æˆåŠŸè½¬æ¢: {ipynb_path}")
                    converted_files.append(ipynb_path)
                else:
                    print(f"âŒ è½¬æ¢å¤±è´¥: {filename}")
                    
            except Exception as e:
                print(f"âŒ è½¬æ¢é”™è¯¯ {filename}: {e}")
    
    print(f"\nğŸ‰ è½¬æ¢å®Œæˆï¼å…±è½¬æ¢ {len(converted_files)} ä¸ªæ–‡ä»¶:")
    for file in converted_files:
        print(f"   ğŸ““ {file}")
    
    return converted_files

def create_complete_colab_notebook():
    """åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„Colabè®­ç»ƒnotebook"""
    
    print("\nğŸš€ åˆ›å»ºå®Œæ•´çš„Colab/Kaggleè®­ç»ƒnotebook...")
    
    # è¯»å–æ ¸å¿ƒè„šæœ¬å†…å®¹
    scripts_to_include = [
        'scripts/improved_stable_diffusion.py',
        'scripts/colab_training.py'
    ]
    
    notebook_cells = []
    
    # æ·»åŠ æ ‡é¢˜å’Œè¯´æ˜
    notebook_cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "# ğŸš€ Complete Stable Diffusion Kanji Generation - Colab/Kaggle\n",
            "\n",
            "**Single file training notebook** - Upload to Colab/Kaggle and start training immediately!\n",
            "\n",
            "## ğŸ¯ Features\n",
            "- âœ… **Complete Training Pipeline**: VAE + UNet + DDPM\n",
            "- ğŸš€ **GPU Optimized**: Auto CUDA/MPS detection\n",
            "- ğŸ’¾ **Auto-save**: Checkpoints every 5 epochs\n",
            "- ğŸ“Š **Real-time Monitoring**: Loss curves and GPU stats\n",
            "- ğŸ”„ **Resume Training**: Continue from any checkpoint\n",
            "- ğŸŒ **Kanji Generation**: Text-to-Kanji capabilities\n",
            "\n",
            "## ğŸš€ Quick Start\n",
            "1. Upload this notebook to Colab/Kaggle\n",
            "2. Select GPU runtime\n",
            "3. Run all cells\n",
            "4. Start training!\n",
            "\n",
            "**Expected Training Time**:\n",
            "- Colab Free (T4): 50 epochs in 2-3 hours\n",
            "- Colab Pro (V100/P100): 50 epochs in 1-1.5 hours\n",
            "- Kaggle (P100): 50 epochs in 1-2 hours"
        ]
    })
    
    # æ·»åŠ ä¾èµ–å®‰è£…
    notebook_cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": ["## ğŸ“¦ Install Dependencies"]
    })
    
    notebook_cells.append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Install required packages\n",
            "!pip install transformers pillow matplotlib scikit-image opencv-python tqdm\n",
            "!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
            "\n",
            "print(\"âœ… Dependencies installed successfully!\")"
        ]
    })
    
    # æ·»åŠ GPUæ£€æŸ¥
    notebook_cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": ["## ğŸ”§ Check GPU and Environment"]
    })
    
    notebook_cells.append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "import torch\n",
            "import os\n",
            "\n",
            "# Check environment\n",
            "is_colab = 'COLAB_GPU' in os.environ\n",
            "is_kaggle = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
            "\n",
            "print(f\"ğŸŒ Environment: {'Colab' if is_colab else 'Kaggle' if is_kaggle else 'Local'}\")\n",
            "print(f\"PyTorch: {torch.__version__}\")\n",
            "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
            "\n",
            "if torch.cuda.is_available():\n",
            "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
            "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
            "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
            "    print(\"ğŸ Apple Silicon (MPS) available\")\n",
            "else:\n",
            "    print(\"âš ï¸ Using CPU (will be slow!)\")"
        ]
    })
    
    # è¯»å–å¹¶æ·»åŠ æ¨¡å‹å®ç°ä»£ç 
    for script_path in scripts_to_include:
        if os.path.exists(script_path):
            with open(script_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # æå–ä¸»è¦ä»£ç éƒ¨åˆ†ï¼ˆå»æ‰importå’Œmainéƒ¨åˆ†ï¼‰
            lines = content.split('\n')
            code_lines = []
            skip_main = False
            
            for line in lines:
                if line.strip().startswith('if __name__'):
                    skip_main = True
                if not skip_main and not line.strip().startswith('#!'):
                    code_lines.append(line)
            
            clean_code = '\n'.join(code_lines)
            
            notebook_cells.append({
                "cell_type": "markdown",
                "metadata": {},
                "source": [f"## ğŸ—ï¸ {os.path.basename(script_path)} Implementation"]
            })
            
            notebook_cells.append({
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [clean_code]
            })
    
    # æ·»åŠ è®­ç»ƒå¯åŠ¨ä»£ç 
    notebook_cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": ["## ğŸš€ Start Training"]
    })
    
    notebook_cells.append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Create trainer and start training\n",
            "if 'ColabOptimizedTrainer' in globals():\n",
            "    trainer = ColabOptimizedTrainer()\n",
            "    trainer.train()\n",
            "else:\n",
            "    print(\"âš ï¸ Trainer class not found. Please run the model implementation cells first.\")"
        ]
    })
    
    # æ·»åŠ ç»“æœä¸‹è½½
    notebook_cells.append({
        "cell_type": "markdown",
        "metadata": {},
        "source": ["## ğŸ“¥ Download Results"]
    })
    
    notebook_cells.append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# Download training results\n",
            "from google.colab import files\n",
            "import zipfile\n",
            "\n",
            "def download_results():\n",
            "    print(\"ğŸ“¥ Preparing results for download...\")\n",
            "    \n",
            "    # Create results zip\n",
            "    with zipfile.ZipFile('training_results.zip', 'w') as zipf:\n",
            "        # Add checkpoints\n",
            "        if os.path.exists('checkpoints'):\n",
            "            for root, dirs, files in os.walk('checkpoints'):\n",
            "                for file in files:\n",
            "                    file_path = os.path.join(root, file)\n",
            "                    zipf.write(file_path, os.path.relpath(file_path, '.'))\n",
            "        \n",
            "        # Add training curves\n",
            "        for img_file in ['training_curve.png', 'loss_curve.png']:\n",
            "            if os.path.exists(img_file):\n",
            "                zipf.write(img_file)\n",
            "        \n",
            "        # Add generated images\n",
            "        for i in range(10):\n",
            "            img_file = f'generated_{i}.png'\n",
            "            if os.path.exists(img_file):\n",
            "                zipf.write(img_file)\n",
            "    \n",
            "    print(\"âœ… Results packaged: training_results.zip\")\n",
            "    \n",
            "    # Download\n",
            "    try:\n",
            "        files.download('training_results.zip')\n",
            "        print(\"ğŸ“¥ Results downloaded successfully!\")\n",
            "    except:\n",
            "        print(\"âš ï¸ Download failed (not in Colab)\")\n",
            "        print(\"ğŸ“ Files are saved in the current directory\")\n",
            "\n",
            "# Download results\n",
            "download_results()"
        ]
    })
    
    # åˆ›å»ºå®Œæ•´çš„notebook
    complete_notebook = {
        "cells": notebook_cells,
        "metadata": {
            "accelerator": "GPU",
            "colab": {
                "gpuType": "T4",
                "provenance": []
            },
            "kernelspec": {
                "display_name": "Python 3",
                "language": "python",
                "name": "python3"
            },
            "language_info": {
                "name": "python",
                "version": "3.8.10"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 0
    }
    
    # ä¿å­˜notebook
    import json
    notebook_path = 'complete_colab_kaggle_training.ipynb'
    with open(notebook_path, 'w', encoding='utf-8') as f:
        json.dump(complete_notebook, f, indent=1, ensure_ascii=False)
    
    print(f"âœ… å®Œæ•´çš„Colab/Kaggle notebookå·²åˆ›å»º: {notebook_path}")
    return notebook_path

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æ‰¹é‡è½¬æ¢Pythonè„šæœ¬ä¸ºJupyter notebook...")
    
    # æ‰¹é‡è½¬æ¢ç°æœ‰è„šæœ¬
    converted_files = batch_convert_to_notebooks()
    
    # åˆ›å»ºå®Œæ•´çš„Colabè®­ç»ƒnotebook
    complete_notebook = create_complete_colab_notebook()
    
    print(f"\nğŸ‰ æ‰€æœ‰è½¬æ¢å®Œæˆï¼")
    print(f"ğŸ““ è½¬æ¢çš„notebookæ–‡ä»¶: {len(converted_files)} ä¸ª")
    print(f"ğŸš€ å®Œæ•´çš„Colab/Kaggleè®­ç»ƒnotebook: {complete_notebook}")
    print(f"\nğŸ“‹ ä½¿ç”¨è¯´æ˜:")
    print(f"   1. ä¸Šä¼  {complete_notebook} åˆ° Google Colab æˆ– Kaggle")
    print(f"   2. é€‰æ‹© GPU è¿è¡Œæ—¶")
    print(f"   3. è¿è¡Œæ‰€æœ‰å•å…ƒæ ¼å¼€å§‹è®­ç»ƒ")
    print(f"   4. è®­ç»ƒå®Œæˆåä¸‹è½½ç»“æœ")
