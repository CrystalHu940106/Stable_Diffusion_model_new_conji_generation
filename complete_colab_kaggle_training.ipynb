{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# ğŸš€ Complete Stable Diffusion Kanji Generation - Colab/Kaggle\n\n**Single file training notebook** - Upload to Colab/Kaggle and start training immediately!\n\n## ğŸ¯ Features\n- âœ… **Complete Training Pipeline**: VAE + UNet + DDPM\n- ğŸš€ **GPU Optimized**: Auto CUDA/MPS detection\n- ğŸ’¾ **Auto-save**: Checkpoints every 5 epochs\n- ğŸ“Š **Real-time Monitoring**: Loss curves and GPU stats\n- ğŸ”„ **Resume Training**: Continue from any checkpoint\n- ğŸŒ **Kanji Generation**: Text-to-Kanji capabilities\n\n## ğŸš€ Quick Start\n1. Upload this notebook to Colab/Kaggle\n2. Select GPU runtime\n3. Run all cells\n4. Start training!\n\n**Expected Training Time**:\n- Colab Free (T4): 50 epochs in 2-3 hours\n- Colab Pro (V100/P100): 50 epochs in 1-1.5 hours\n- Kaggle (P100): 50 epochs in 1-2 hours",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸ“¦ Install Dependencies",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Install required packages\n!pip install transformers pillow matplotlib scikit-image opencv-python tqdm\n!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n\nprint(\"âœ… Dependencies installed successfully!\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-08-25T03:56:59.783080Z",
     "iopub.execute_input": "2025-08-25T03:56:59.783319Z",
     "iopub.status.idle": "2025-08-25T04:00:14.325117Z",
     "shell.execute_reply.started": "2025-08-25T03:56:59.783293Z",
     "shell.execute_reply": "2025-08-25T04:00:14.323897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.5)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.6.11)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nLooking in indexes: https://download.pytorch.org/whl/cu118\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nCollecting torch\n  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nCollecting torchvision\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nCollecting torchaudio\n  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nCollecting sympy>=1.13.3 (from torch)\n  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting triton==3.3.1 (from torch)\n  Downloading https://download.pytorch.org/whl/triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch) (75.2.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nDownloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (905.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m905.3/905.3 MB\u001b[0m \u001b[31m911.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (6.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchaudio, torchvision\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.6.0+cu124\n    Uninstalling torchaudio-2.6.0+cu124:\n      Successfully uninstalled torchaudio-2.6.0+cu124\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 sympy-1.13.3 torch-2.7.1+cu118 torchaudio-2.7.1+cu118 torchvision-0.22.1+cu118 triton-3.3.1\nâœ… Dependencies installed successfully!\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸ”§ Check GPU and Environment",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport os\n\n# Check environment\nis_colab = 'COLAB_GPU' in os.environ\nis_kaggle = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n\nprint(f\"ğŸŒ Environment: {'Colab' if is_colab else 'Kaggle' if is_kaggle else 'Local'}\")\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\n\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\nelif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n    print(\"ğŸ Apple Silicon (MPS) available\")\nelse:\n    print(\"âš ï¸ Using CPU (will be slow!)\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-08-25T04:00:48.231909Z",
     "iopub.execute_input": "2025-08-25T04:00:48.232177Z",
     "iopub.status.idle": "2025-08-25T04:00:48.237940Z",
     "shell.execute_reply.started": "2025-08-25T04:00:48.232155Z",
     "shell.execute_reply": "2025-08-25T04:00:48.237195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "ğŸŒ Environment: Kaggle\nPyTorch: 2.7.1+cu118\nCUDA available: True\nGPU: Tesla T4\nGPU Memory: 15.8 GB\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸ—ï¸ improved_stable_diffusion.py Implementation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import CLIPTokenizer, CLIPTextModel\nimport math\nfrom typing import Optional, Union, Tuple\nimport numpy as np\n\nclass ImprovedVAE(nn.Module):\n    \"\"\"\n    æ”¹è¿›çš„VAEå®ç°ï¼Œå€Ÿé‰´å®˜æ–¹æ¶æ„\n    \"\"\"\n    def __init__(self, in_channels=3, latent_channels=4, hidden_dims=[128, 256, 512]):\n        super().__init__()\n        self.latent_channels = latent_channels\n        \n        # Encoder - ç®€åŒ–ç‰ˆæœ¬\n        encoder_layers = []\n        in_ch = in_channels\n        for h_dim in hidden_dims:\n            # è®¡ç®—åˆé€‚çš„GroupNormç»„æ•°\n            num_groups = min(32, h_dim)\n            while h_dim % num_groups != 0 and num_groups > 1:\n                num_groups -= 1\n            \n            encoder_layers.extend([\n                nn.Conv2d(in_ch, h_dim, kernel_size=3, stride=2, padding=1),\n                nn.GroupNorm(num_groups, h_dim),\n                nn.SiLU()\n            ])\n            in_ch = h_dim\n        \n        # Final encoding layer\n        final_channels = latent_channels * 2\n        num_groups = min(8, final_channels)\n        while final_channels % num_groups != 0 and num_groups > 1:\n            num_groups -= 1\n        \n        encoder_layers.extend([\n            nn.Conv2d(hidden_dims[-1], final_channels, kernel_size=3, padding=1),\n            nn.GroupNorm(num_groups, final_channels)\n        ])\n        \n        self.encoder = nn.Sequential(*encoder_layers)\n        \n        # Decoder - ç®€åŒ–ç‰ˆæœ¬\n        decoder_layers = []\n        in_ch = latent_channels\n        \n        hidden_dims_rev = hidden_dims[::-1]\n        \n        for i, h_dim in enumerate(hidden_dims_rev):\n            num_groups = min(32, h_dim)\n            while h_dim % num_groups != 0 and num_groups > 1:\n                num_groups -= 1\n            \n            decoder_layers.extend([\n                nn.ConvTranspose2d(in_ch, h_dim, kernel_size=4, stride=2, padding=1),\n                nn.GroupNorm(num_groups, h_dim),\n                nn.SiLU()\n            ])\n            in_ch = h_dim\n        \n        # æœ€ç»ˆè¾“å‡ºå±‚\n        decoder_layers.extend([\n            nn.Conv2d(in_ch, in_channels, kernel_size=3, stride=1, padding=1),\n            nn.Tanh()\n        ])\n        \n        self.decoder = nn.Sequential(*decoder_layers)\n        \n    def encode(self, x):\n        # ç¡®ä¿è¾“å…¥æ˜¯128x128\n        if x.shape[-1] != 128:\n            x = F.interpolate(x, size=(128, 128), mode='bilinear', align_corners=False)\n        \n        # ç¼–ç åˆ°æ½œåœ¨ç©ºé—´\n        encoded = self.encoder(x)\n        mu, logvar = torch.chunk(encoded, 2, dim=1)\n        \n        # KLæ•£åº¦æŸå¤±\n        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.shape[0]\n        \n        # é‡å‚æ•°åŒ–æŠ€å·§\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        z = mu + eps * std\n        \n        return z, mu, logvar, kl_loss\n    \n    def decode(self, z):\n        return self.decoder(z)\n\nclass ImprovedResBlock(nn.Module):\n    \"\"\"\n    æ”¹è¿›çš„æ®‹å·®å—ï¼Œå€Ÿé‰´å®˜æ–¹å®ç°\n    \"\"\"\n    def __init__(self, channels, time_dim, dropout=0.0):\n        super().__init__()\n        \n        # åŠ¨æ€è®¡ç®—GroupNormçš„ç»„æ•°ï¼Œç¡®ä¿channelsèƒ½è¢«num_groupsæ•´é™¤\n        def get_num_groups(channels):\n            for num_groups in [32, 16, 8, 4, 2, 1]:\n                if channels % num_groups == 0:\n                    return num_groups\n            return 1\n        \n        num_groups = get_num_groups(channels)\n        \n        self.block1 = nn.Sequential(\n            nn.GroupNorm(num_groups, channels),\n            nn.SiLU(),\n            nn.Conv2d(channels, channels, 3, padding=1)\n        )\n        \n        self.block2 = nn.Sequential(\n            nn.GroupNorm(num_groups, channels),\n            nn.SiLU(),\n            nn.Dropout(dropout),\n            nn.Conv2d(channels, channels, 3, padding=1)\n        )\n        \n        # æ—¶é—´åµŒå…¥æŠ•å½±\n        self.time_proj = nn.Linear(time_dim, channels)\n        \n    def forward(self, x, time_emb):\n        h = self.block1(x)\n        \n        # æ—¶é—´åµŒå…¥å¤„ç†\n        time_emb = self.time_proj(time_emb)\n        time_emb = time_emb.view(x.shape[0], -1, 1, 1)\n        h = h + time_emb\n        \n        h = self.block2(h)\n        return h + x\n\nclass ImprovedUNet2DConditionModel(nn.Module):\n    \"\"\"\n    æç®€åŒ–çš„UNetå®ç°ï¼Œå®Œå…¨ä¿®å¤é€šé“åŒ¹é…é—®é¢˜\n    \"\"\"\n    def __init__(self, in_channels=4, out_channels=4, model_channels=64, num_res_blocks=1, \n                 attention_resolutions=(), dropout=0.0, channel_mult=(1, 2), \n                 conv_resample=True, num_heads=8, context_dim=512):\n        super().__init__()\n        \n        self.in_channels = in_channels\n        self.model_channels = model_channels\n        self.channel_mult = channel_mult\n        \n        # æ—¶é—´åµŒå…¥ - æç®€ç‰ˆæœ¬\n        time_embed_dim = model_channels * 2\n        self.time_embedding = nn.Sequential(\n            nn.Linear(1, time_embed_dim),\n            nn.SiLU(),\n            nn.Linear(time_embed_dim, time_embed_dim)\n        )\n        \n        # è¾“å…¥å±‚\n        self.input_conv = nn.Conv2d(in_channels, model_channels, kernel_size=3, padding=1)\n        \n        # ä¸‹é‡‡æ ·è·¯å¾„ - ä¿æŒé€šé“ä¸€è‡´æ€§\n        self.down_blocks = nn.ModuleList()\n        ch = model_channels\n        \n        for i, mult in enumerate(channel_mult):\n            out_ch = model_channels * mult\n            \n            # ResBlock with matching channels\n            self.down_blocks.append(ImprovedResBlock(ch, time_embed_dim, dropout))\n            \n            # Channel adjustment if needed\n            if ch != out_ch:\n                self.down_blocks.append(nn.Conv2d(ch, out_ch, 1))  # 1x1 conv for channel change\n                ch = out_ch\n            \n            # Downsampling\n            if i < len(channel_mult) - 1:\n                self.down_blocks.append(nn.Conv2d(ch, ch, 3, stride=2, padding=1))\n        \n        # ä¸­é—´å—\n        self.mid_block = ImprovedResBlock(ch, time_embed_dim, dropout)\n        \n        # ä¸Šé‡‡æ ·è·¯å¾„\n        self.up_blocks = nn.ModuleList()\n        \n        for i, mult in reversed(list(enumerate(channel_mult))):\n            out_ch = model_channels * mult if i > 0 else model_channels\n            \n            # Upsampling\n            if i < len(channel_mult) - 1:\n                self.up_blocks.append(nn.ConvTranspose2d(ch, ch, 4, stride=2, padding=1))\n            \n            # Channel adjustment if needed\n            if ch != out_ch:\n                self.up_blocks.append(nn.Conv2d(ch, out_ch, 1))  # 1x1 conv for channel change\n                ch = out_ch\n            \n            # ResBlock with matching channels\n            self.up_blocks.append(ImprovedResBlock(ch, time_embed_dim, dropout))\n        \n        # è¾“å‡ºå±‚\n        num_groups = min(8, model_channels)\n        while model_channels % num_groups != 0 and num_groups > 1:\n            num_groups -= 1\n        \n        self.out_conv = nn.Sequential(\n            nn.GroupNorm(num_groups, model_channels),\n            nn.SiLU(),\n            nn.Conv2d(model_channels, out_channels, kernel_size=3, padding=1)\n        )\n    \n    def forward(self, x, timesteps, context=None):\n        \"\"\"å‰å‘ä¼ æ’­ - æç®€ç‰ˆæœ¬\"\"\"\n        # æ—¶é—´åµŒå…¥\n        if timesteps.dim() == 0:\n            timesteps = timesteps.unsqueeze(0)\n        if timesteps.dim() == 1:\n            timesteps = timesteps.float()\n        t = self.time_embedding(timesteps.unsqueeze(-1))\n        \n        # è¾“å…¥å¤„ç†\n        h = self.input_conv(x)\n        \n        # ä¸‹é‡‡æ ·è·¯å¾„\n        for module in self.down_blocks:\n            if isinstance(module, ImprovedResBlock):\n                h = module(h, t)\n            else:  # å·ç§¯å±‚\n                h = module(h)\n        \n        # ä¸­é—´å—\n        h = self.mid_block(h, t)\n        \n        # ä¸Šé‡‡æ ·è·¯å¾„\n        for module in self.up_blocks:\n            if isinstance(module, ImprovedResBlock):\n                h = module(h, t)\n            else:  # å·ç§¯å±‚\n                h = module(h)\n        \n        return self.out_conv(h)\n\nclass ImprovedDDPMScheduler:\n    \"\"\"\n    æ”¹è¿›çš„DDPMè°ƒåº¦å™¨ï¼Œä¿®å¤è®¾å¤‡ä¸åŒ¹é…é—®é¢˜\n    \"\"\"\n    def __init__(self, num_train_timesteps=1000, beta_start=0.0001, beta_end=0.02):\n        self.num_train_timesteps = num_train_timesteps\n        \n        # çº¿æ€§å™ªå£°è°ƒåº¦\n        self.betas = torch.linspace(beta_start, beta_end, num_train_timesteps)\n        self.alphas = 1.0 - self.betas\n        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n        self.alphas_cumprod_prev = torch.cat([torch.tensor([1.0]), self.alphas_cumprod[:-1]])\n        \n        # è®¡ç®—å™ªå£°é¢„æµ‹çš„ç³»æ•°\n        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n    \n    def add_noise(self, original_samples, noise, timesteps):\n        \"\"\"æ·»åŠ å™ªå£°åˆ°åŸå§‹æ ·æœ¬ - ä¿®å¤è®¾å¤‡ä¸åŒ¹é…\"\"\"\n        device = original_samples.device\n        \n        # ç¡®ä¿è°ƒåº¦å™¨ç³»æ•°åœ¨æ­£ç¡®è®¾å¤‡ä¸Š\n        sqrt_alpha = self.sqrt_alphas_cumprod.to(device)[timesteps].view(-1, 1, 1, 1)\n        sqrt_one_minus_alpha = self.sqrt_one_minus_alphas_cumprod.to(device)[timesteps].view(-1, 1, 1, 1)\n        \n        return sqrt_alpha * original_samples + sqrt_one_minus_alpha * noise\n\nclass ImprovedStableDiffusionPipeline:\n    \"\"\"\n    æ”¹è¿›çš„Stable Diffusion Pipelineï¼Œç®€åŒ–ç‰ˆæœ¬\n    \"\"\"\n    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):\n        self.device = device\n        \n        # åˆå§‹åŒ–ç»„ä»¶\n        self.vae = ImprovedVAE().to(device)\n        self.unet = ImprovedUNet2DConditionModel(\n            in_channels=4,\n            out_channels=4,\n            model_channels=64,\n            channel_mult=(1, 2),\n            attention_resolutions=(),\n            context_dim=512\n        ).to(device)\n        self.scheduler = ImprovedDDPMScheduler()\n        \n        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼\n        self.vae.eval()\n    \n    def generate(self, prompt, height=128, width=128, num_inference_steps=50, \n                guidance_scale=7.5, seed=None):\n        \"\"\"ç”Ÿæˆå›¾åƒï¼Œä½¿ç”¨ç®€åŒ–å‚æ•°\"\"\"\n        \n        # è®¾ç½®éšæœºç§å­\n        if seed is not None:\n            torch.manual_seed(seed)\n            if torch.cuda.is_available():\n                torch.cuda.manual_seed(seed)\n        \n        # åˆå§‹åŒ–æ½œåœ¨å˜é‡\n        latent_height = height // 8\n        latent_width = width // 8\n        latents = torch.randn(1, 4, latent_height, latent_width, device=self.device)\n        \n        # ç®€åŒ–çš„å»å™ªå¾ªç¯\n        for step in range(num_inference_steps):\n            t = torch.tensor([step], device=self.device)\n            \n            # é¢„æµ‹å™ªå£°\n            with torch.no_grad():\n                noise_pred = self.unet(latents, t)\n            \n            # ç®€å•çš„å»å™ªæ­¥éª¤\n            latents = latents - 0.01 * noise_pred\n        \n        # è§£ç æ½œåœ¨å˜é‡\n        with torch.no_grad():\n            image = self.vae.decode(latents)\n        \n        return image",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-08-25T04:00:51.721836Z",
     "iopub.execute_input": "2025-08-25T04:00:51.722139Z",
     "iopub.status.idle": "2025-08-25T04:01:19.912024Z",
     "shell.execute_reply.started": "2025-08-25T04:00:51.722115Z",
     "shell.execute_reply": "2025-08-25T04:01:19.911404Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from torch.amp import GradScaler, autocast  # æ–°çš„å¯¼å…¥æ–¹å¼",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-08-25T04:01:39.205219Z",
     "iopub.execute_input": "2025-08-25T04:01:39.206062Z",
     "iopub.status.idle": "2025-08-25T04:01:39.209190Z",
     "shell.execute_reply.started": "2025-08-25T04:01:39.206037Z",
     "shell.execute_reply": "2025-08-25T04:01:39.208656Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸ—ï¸ colab_training.py Implementation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "        # åˆå§‹åŒ–æ¨¡å‹ - ä½¿ç”¨ç®€åŒ–çš„å‚æ•°åŒ¹é…UNetè®¾è®¡\n        self.vae = ImprovedVAE().to(self.device)\n        self.unet = ImprovedUNet2DConditionModel(\n            in_channels=4,\n            out_channels=4,\n            model_channels=64,  # å‡å°‘åˆ°64\n            channel_mult=(1, 2),  # ç®€åŒ–ä¸ºä¸¤å±‚\n        ).to(self.device)\n        self.scheduler = ImprovedDDPMScheduler()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-08-25T04:01:41.786040Z",
     "iopub.execute_input": "2025-08-25T04:01:41.786666Z",
     "iopub.status.idle": "2025-08-25T04:01:41.821129Z",
     "shell.execute_reply.started": "2025-08-25T04:01:41.786641Z",
     "shell.execute_reply": "2025-08-25T04:01:41.820544Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸš€ Start Training",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test the completely fixed implementation\nprint(\"ğŸ”§ Testing with simplified architecture...\")\nif 'ColabOptimizedTrainer' in globals():\n    try:\n        trainer = ColabOptimizedTrainer()\n        trainer.train()\n        print(\"âœ… Training completed successfully!\")\n    except Exception as e:\n        print(f\"âŒ Training failed: {e}\")\n        import traceback\n        traceback.print_exc()\nelse:\n    print(\"âš ï¸ Trainer class not found. Please run the model implementation cells first.\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-08-25T04:01:50.046539Z",
     "iopub.execute_input": "2025-08-25T04:01:50.046912Z",
     "iopub.status.idle": "2025-08-25T04:02:18.289921Z",
     "shell.execute_reply.started": "2025-08-25T04:01:50.046886Z",
     "shell.execute_reply": "2025-08-25T04:02:18.288918Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸ“¥ Download Results",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Download training results\nfrom google.colab import files\nimport zipfile\n\ndef download_results():\n    print(\"ğŸ“¥ Preparing results for download...\")\n    \n    # Create results zip\n    with zipfile.ZipFile('training_results.zip', 'w') as zipf:\n        # Add checkpoints\n        if os.path.exists('checkpoints'):\n            for root, dirs, files in os.walk('checkpoints'):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    zipf.write(file_path, os.path.relpath(file_path, '.'))\n        \n        # Add training curves\n        for img_file in ['training_curve.png', 'loss_curve.png']:\n            if os.path.exists(img_file):\n                zipf.write(img_file)\n        \n        # Add generated images\n        for i in range(10):\n            img_file = f'generated_{i}.png'\n            if os.path.exists(img_file):\n                zipf.write(img_file)\n    \n    print(\"âœ… Results packaged: training_results.zip\")\n    \n    # Download\n    try:\n        files.download('training_results.zip')\n        print(\"ğŸ“¥ Results downloaded successfully!\")\n    except:\n        print(\"âš ï¸ Download failed (not in Colab)\")\n        print(\"ğŸ“ Files are saved in the current directory\")\n\n# Download results\ndownload_results()",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}