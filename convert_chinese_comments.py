#!/usr/bin/env python3
"""
Convert Chinese comments to English in all project files
"""

import os
import re
import json
from pathlib import Path

# Translation mapping for common Chinese terms
TRANSLATIONS = {
    # Basic terms
    "è¯Šæ–­": "diagnose",
    "æ¨¡å‹": "model", 
    "æ£€æŸ¥": "check",
    "è®­ç»ƒ": "training",
    "ç”Ÿæˆ": "generation",
    "ä¿®å¤": "fix",
    "é—®é¢˜": "issue",
    "ç¡®ä¿": "ensure",
    "æ·»åŠ ": "add",
    "å®šä¹‰": "define", 
    "å®Œæˆ": "complete",
    "æµ‹è¯•": "test",
    "ä½¿ç”¨": "use",
    "åˆ›å»º": "create",
    "æ‰«æ": "scan",
    "æ•´ä¸ª": "entire",
    "é¡¹ç›®": "project", 
    "åŒ…": "package",
    "èƒ½": "can",
    "åœ¨": "in",
    "ä¸Š": "on",
    "è¿è¡Œ": "run",
    "çš„": "of",
    "é‡ç‚¹": "key",
    "è½¬æ¢": "convert",
    "ç›¸å…³": "related",
    "è„šæœ¬": "script",
    "ä¸€ä¸ª": "a",
    "å®Œæ•´": "complete",
    "è¯»å–": "read",
    "å¹¶": "and",
    "å®ç°": "implementation",
    "ä»£ç ": "code",
    "å¯åŠ¨": "startup",
    "æ‰€æœ‰": "all",
    "å•å…ƒæ ¼": "cells",
    "å¼€å§‹": "start",
    "å¼€å§‹è®­ç»ƒ": "start training",
    
    # Technical terms
    "è´¨é‡": "quality",
    "æ‰¾å‡º": "find out",
    "é»‘ç™½è‰²": "black and white",
    "çš„åŸå› ": "cause",
    "æƒé‡": "weights",
    "åˆ†å¸ƒ": "distribution",
    "èŒƒå›´": "range",
    "æ ‡å‡†å·®": "standard deviation",
    "é‡å»º": "reconstruction",
    "èƒ½åŠ›": "capability",
    "è¯¯å·®": "error",
    "è¿‡å¤§": "too large",
    "å¯èƒ½": "may",
    "å½±å“": "affect", 
    "å™ªå£°": "noise",
    "é¢„æµ‹": "prediction",
    "æ¡ä»¶": "condition",
    "æ•ˆæœ": "effect",
    "å¾®å¼±": "weak",
    "ä¸è¶³": "insufficient",
    "å…¨æ˜¯": "all are",
    "é¥±å’Œ": "saturation",
    "æˆ–": "or",
    "åˆå§‹åŒ–": "initialization",
    
    # Method names
    "ç”¨ä¸åŒéšæœºç§å­æµ‹è¯•ç”Ÿæˆ": "test generation with different random seeds",
    "çœ‹æ˜¯å¦æ€»æ˜¯é»‘ç™½è‰²": "check if always black and white",
    "å¤šä¸ª": "multiple",
    "éšæœºç§å­": "random seed",
    "è®¾ç½®": "set",
    "ä¸åŒ": "different",
    "è¾“å‡º": "output",
    "åˆ°": "to",
    "æ§åˆ¶å°": "console",
    "å½“": "when",
    "æ‰§è¡Œ": "executed",
    "å¹³å‡å€¼": "mean value",
    "æœ€å°å€¼": "minimum value", 
    "æœ€å¤§å€¼": "maximum value",
    "å¦‚æœ": "if",
    "å°äº": "less than",
    "æ ‡å‡†å·®è¿‡å°": "standard deviation too small",
    "å¯èƒ½æ˜¯çº¯è‰²": "likely solid color",
    "å›¾åƒ": "image",
    
    # Common phrases
    "è¿™æ ·å¯ä»¥": "this can",
    "é¿å…": "avoid",
    "åŒæ—¶": "while",
    "ä¿æŒ": "maintain",
    "åœ¨åˆç†èŒƒå›´å†…": "within reasonable range",
    "è€Œä¸æ˜¯": "rather than",
    "è½¯é¥±å’Œ": "soft saturation",
    "æ›´åˆç†çš„": "more reasonable",
    "è°ƒåº¦": "scheduling",
    "æ›¿ä»£": "replace",
    "çº¿æ€§è°ƒåº¦": "linear scheduling",
    "æ›´": "more",
    "ç¨³å®š": "stable",
    "ç³»æ•°": "coefficient",
    "ç‰ˆæœ¬": "version",
    "ä½¿ç”¨": "using",
    "æ¸©å’Œçš„": "gentle",
    "æ¿€æ´»å‡½æ•°": "activation function",
    "å®¹æ˜“é¥±å’Œåœ¨": "easily saturates at",
    "æ›¿æ¢": "replace",
    "å¯å­¦ä¹ çš„": "learnable",
    "ç¼©æ”¾å› å­": "scaling factor",
    "åç§»": "offset",
    "è§£ç ": "decode",
    "ä½¿ç”¨å¯å­¦ä¹ çš„è½¯æ€§æ¿€æ´»å‡½æ•°": "use learnable soft activation function",
    "ä»£æ›¿ç¡¬æ€§": "instead of hard",
    "è¿™æ ·å¯ä»¥é¿å…é¥±å’Œé—®é¢˜": "this avoids saturation issues",
    "æ›´æ¸©å’Œçš„": "more gentle",
    "æ›´åˆç†çš„å™ªå£°è°ƒåº¦": "more reasonable noise scheduling",
    "é¿å…å™ªå£°è¿‡å¼º": "avoid excessive noise",
    "ä¿®å¤DDPMè°ƒåº¦å™¨": "fix DDPM scheduler",
}

def translate_chinese_text(text):
    """Translate Chinese text to English using the mapping"""
    # Sort by length (longest first) to handle multi-character terms first
    sorted_translations = sorted(TRANSLATIONS.items(), key=lambda x: len(x[0]), reverse=True)
    
    result = text
    for chinese, english in sorted_translations:
        result = result.replace(chinese, english)
    
    return result

def convert_python_file(file_path):
    """Convert Chinese comments in Python files"""
    print(f"Processing Python file: {file_path}")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Find Chinese characters in comments
    chinese_pattern = r'(#.*?[\u4e00-\u9fff].*?)$'
    lines = content.split('\n')
    modified = False
    
    for i, line in enumerate(lines):
        # Check if line contains Chinese characters in comments
        if '#' in line and re.search(r'[\u4e00-\u9fff]', line):
            # Extract comment part
            if '#' in line:
                code_part = line[:line.find('#')]
                comment_part = line[line.find('#'):]
                
                # Translate the comment
                translated_comment = translate_chinese_text(comment_part)
                new_line = code_part + translated_comment
                
                if new_line != line:
                    print(f"  Line {i+1}: {line.strip()}")
                    print(f"    -> {new_line.strip()}")
                    lines[i] = new_line
                    modified = True
    
    # Also check for Chinese in docstrings
    docstring_pattern = r'"""(.*?)"""'
    new_content = '\n'.join(lines)
    
    def translate_docstring(match):
        docstring = match.group(1)
        if re.search(r'[\u4e00-\u9fff]', docstring):
            return '"""' + translate_chinese_text(docstring) + '"""'
        return match.group(0)
    
    translated_content = re.sub(docstring_pattern, translate_docstring, new_content, flags=re.DOTALL)
    
    if translated_content != new_content:
        modified = True
    
    if modified:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(translated_content)
        print(f"  âœ… Updated {file_path}")
        return True
    else:
        print(f"  âœ… No Chinese comments found in {file_path}")
        return False

def convert_notebook_file(file_path):
    """Convert Chinese comments in Jupyter notebook files"""
    print(f"Processing notebook file: {file_path}")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            notebook = json.load(f)
    except json.JSONDecodeError as e:
        print(f"  âŒ JSON decode error in {file_path}: {e}")
        print(f"  âš ï¸  Skipping malformed notebook file")
        return False
    
    modified = False
    
    for cell_idx, cell in enumerate(notebook.get('cells', [])):
        if cell.get('cell_type') == 'code':
            source = cell.get('source', [])
            if isinstance(source, str):
                source = [source]
            
            for line_idx, line in enumerate(source):
                # Check for Chinese characters in comments
                if '#' in line and re.search(r'[\u4e00-\u9fff]', line):
                    # Extract and translate comment
                    if '#' in line:
                        code_part = line[:line.find('#')]
                        comment_part = line[line.find('#'):]
                        translated_comment = translate_chinese_text(comment_part)
                        new_line = code_part + translated_comment
                        
                        if new_line != line:
                            print(f"  Cell {cell_idx}, Line {line_idx}: {line.strip()}")
                            print(f"    -> {new_line.strip()}")
                            source[line_idx] = new_line
                            modified = True
                
                # Also check for Chinese in string literals that might be comments
                if re.search(r'[\u4e00-\u9fff]', line):
                    # Handle print statements and docstrings
                    if 'print(' in line or '"""' in line or "'''" in line:
                        translated_line = translate_chinese_text(line)
                        if translated_line != line:
                            print(f"  Cell {cell_idx}, Line {line_idx}: {line.strip()}")
                            print(f"    -> {translated_line.strip()}")
                            source[line_idx] = translated_line
                            modified = True
            
            cell['source'] = source
    
    if modified:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(notebook, f, indent=1, ensure_ascii=False)
        print(f"  âœ… Updated {file_path}")
        return True
    else:
        print(f"  âœ… No Chinese comments found in {file_path}")
        return False

def main():
    """Main function to convert Chinese comments in all files"""
    project_root = Path("/Users/hu.crystal/Documents/NLP/Question2")
    
    print("ğŸ”§ Converting Chinese comments to English...")
    print(f"ğŸ“ Project root: {project_root}")
    
    total_files = 0
    modified_files = 0
    
    # Process Python files
    for py_file in project_root.rglob("*.py"):
        total_files += 1
        if convert_python_file(py_file):
            modified_files += 1
    
    # Process Jupyter notebook files
    for nb_file in project_root.rglob("*.ipynb"):
        total_files += 1
        if convert_notebook_file(nb_file):
            modified_files += 1
    
    print(f"\nâœ… Conversion complete!")
    print(f"ğŸ“Š Files processed: {total_files}")
    print(f"ğŸ“ Files modified: {modified_files}")
    print(f"ğŸ“ˆ Files unchanged: {total_files - modified_files}")

if __name__ == "__main__":
    main()